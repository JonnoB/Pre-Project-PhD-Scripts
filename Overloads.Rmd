---
title: "Untitled"
author: "Jonathan Bourne"
date: "7 January 2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

This code explores the effect of what is removed on the amount of overloads/islands/targeted on the system

#Setup Block

```{r}

packages <- c("tidyverse", "igraph","readr","readxl", "broom", "zoo", "stringr", "xtable", "geomnet", "ggnetwork", "rlang", "animation", "ggridges", "poweRlaw", "Rtsne", "caret", "ranger", "xtable",  "modelr", "yardstick", "sf", "rgdal", "ggtern")

new.packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

#ggtree needs to be installed speratly 
# if (!requireNamespace("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
# BiocManager::install("ggtree", version = "3.8")
#devtools::install_github("eliocamp/ggnewscale@v0.1.0")
#devtools::install_github("eliocamp/ggnewscale")
library(ggtree)
library(ape)
library(ggnewscale)


sapply(packages, library, character.only = TRUE)


lapply(packages, library, character.only = TRUE)
library(PowerGridNetworking)

#Set up file system to read the correct folders this switches between aws and windows mode

basewd <- "/home/jonno/Dropbox/Jonathan_Bourne_Phd_Folder"
datafile <- "/home/jonno/Dropbox/Jonathan_Bourne_Phd_Folder/ETYSAppendixB"
LatexFolder <- "/home/jonno/Dropbox/Apps/ShareLaTeX/Overloads and Failure groups" 
FiguresFolder <- file.path(LatexFolder, "Figures")
TablesFolder <- file.path(LatexFolder, "Tables")
MatricesFolder <- file.path(LatexFolder, "Matrices")
Tariff <- file.path(basewd,"Tariff and Transport")
PLwd <- "/media/jonno/Seagate Expansion Drive/Overloads"
Deletion_Order_Folder <-  file.path("/home/jonno/Dropbox/AWS_Simulation_Files") #Only one of the deletion order folders is needed. Either Nodes or Edges


#Load necessary datasets and great the base powergrid network
source(file.path("/home/jonno/ProportionalLoading", "CreateGBase.R"))

#Load some other useful functions
list.files("/home/jonno/Useful_PhD__R_Functions", pattern = ".R", full.names = T) %>%
  walk(~source(.x))

```

#Set up Graph
```{r}

g <- RemoveDeadEnds(gbase) #remove non-valid ends from the graph
#Ensure there is powerflow
SlackRef <- SlackRefFunc(g) #find the most appropriate node to be the slack bus
g <- PowerFlow(g, SlackRef$name) #calculate power flow

```


#Get Removal Counts
gets the removal method for each node and edge

```{r}

OverloadType <- list.files(Deletion_Order_Folder, 
           pattern = "RandomAttack_", 
           full.names = TRUE) %>%
  map_df(~{
    print(.x)
    list.files(.x, full.names = T) %>%
      map_df(~{
        readRDS(.x) %>%
          #filter(type == "Edge") %>%
          group_by(Name, RemovalType, type) %>%
          summarise(counts = n()) %>%
          spread(key = RemovalType, value = counts, fill = 0) 
      })
    
  }) %>%
  group_by(Name, type) %>%
  summarise_all(sum)

  
  OverloadType %>%
    filter(type == "Node") %>%
  ggtern(aes(Islanded,  Targeted, Overloaded)) + 
    geom_point() +
    ggtitle("Ternary plot of the different failure types")
  
LongProb <-    OverloadType %>%
    filter(type == "Edge") %>%
  select(-type) %>%
    gather(key = FailureType, value = value, -Name) %>% 
    mutate(Perc = value/10000) 
  
  LongProb %>%
    ggplot(aes(x = Perc, colour = FailureType)) + 
    geom_density() +
    labs(title = "Probability density of edge failure type", x = "Proability of failure")
    

Mapdf <- MakeMapDF(g, read_csv(file.path(basewd, "point.csv")))  %>%
  left_join(LongProb, by = c("Link"="Name"))
  
#using the actual value as well as the rank is interesting, but you need to change the midpoint value
Mapdf %>%
  filter(!is.na(Perc)) %>%
  group_by(FailureType) %>%
  mutate(rank = ntile(Perc, 100)) %>%
  ungroup %>%
    ggplot(aes(x = Latitude, y = Longitude)) + 
  geom_line(aes(colour = rank, group = Link)) + 
   facet_grid(PositionType~FailureType) +
  scale_color_viridis_c()
ggsave(file.path(FiguresFolder, "LineRemovalRankMap.pdf"))

```


#Map Metrics
What is the relationship between centrality and e-centrality and loss mode
```{r}

  ElecCen1 <- ElectricalCentrality(g)

ElecCen1$EdgeEC
ElecCen1$NodeEC

test   <- tibble(degree = degree(g), 
   EntropicDeg = EntropicDegree(g, Scale = T), 
   EntropicPower = EntropicDegree(g,  value = "PowerFlow", Scale = TRUE),
   ElecCen = ElecCen1$NodeEC$NodeEC,
   Cent = betweenness(g, normalized = T)
   ) %>%
     mutate_all(~{ifelse(is.finite(.), ., 0)}) %>%
  mutate(Name = get.vertex.attribute(g, "name")) %>%
  left_join(OverloadType %>% filter(type =="Node")) %>%
  select(-Name,-type) %>%
  filter(complete.cases(.))
   

#Degree correlates strongly with centrality
#Degree and centrality are both negatively corellated with Islanding and positively corellated with targetting
#there is only a very weak negative corellation between overloading and degree
cor(test)

EdgeCharacteristics <- ElecCen1$EdgeEC %>%
  rename(Name = Edgename) %>%
  left_join(OverloadType %>% filter(type == "Edge")) %>%
  left_join(tibble(Name = get.edge.attribute(g, "name"), 
                   Centrality = edge_betweenness(g, directed = F),
                   PowerFlow = abs(get.edge.attribute(g, "PowerFlow")),
                   Link.Limit = get.edge.attribute(g, "Link.Limit"))) %>%
filter(complete.cases(.)) %>%
  mutate(LineLoad = Link.Limit/PowerFlow)


EdgeCharacteristics %>%
  select(-Name, -type) %>%
  cor(.,method =  "spearman")


EdgeCharacteristics %>%
  ggplot(aes(x = ElectricalCentrality, y = Link.Limit)) + geom_point()


MetricMap <- EdgeCharacteristics %>%
  select(Link = Name, ElectricalCentrality, Centrality, PowerFlow, LineLoad) %>%
  gather(key = metric, value = value, - Link) %>%
  left_join(MakeMapDF(g, read_csv(file.path(basewd, "point.csv"))),. )


MetricMap %>%
  filter(!is.na(value)) %>%
  group_by(metric) %>%
  mutate(rank = ntile(value, 100)) %>%
  ungroup %>%
    ggplot(aes(x = Latitude, y = Longitude)) + 
  geom_line(aes(colour = rank, group = Link)) + 
   facet_grid(PositionType~metric) +
  scale_color_viridis_c() +
  labs(ttile = "Metric Line map")
ggsave(file.path(FiguresFolder, "MetricMap.pdf"))

```

#Check model accuracy


##create models
```{r}
AlphaOrder <- c("alpha value 1","alpha value 1.05","alpha value 1.1","alpha value 1.2","alpha value 1.5","alpha value 2" ,"alpha value 3","alpha value 5","alpha value 6","alpha value 7","alpha value 10","alpha value 15","alpha value 20","alpha value 50","Topological" ,"PF Model", "Volt PF Model")  


ModelInputVars <- g %>% as_data_frame %>% left_join(.,  ElectricalCentrality(g)$EdgeEC %>% 
                rename(Elec_Centrality = ElectricalCentrality, Link = Edgename)) %>%
  mutate(absPF = abs(PowerFlow),
         Voltage = as.factor(Voltage),
         Centrality =log10(edge_betweenness(g)+1),
         LengthQuart = ntile(Length, 4),
         absPFQuart = ntile(absPF, 4),
         LogLink.Limit = log10(Link.Limit)) 

#Create set of formula to model line limits
FormulaDF <- formulas(~LogLink.Limit, 
         Voltage_Only = ~ Voltage,
         VoltageLength = ~ Voltage + Length,
         VoltElecCent = ~ Voltage + Elec_Centrality,
         VoltPF = ~ Voltage + absPF,
         PF_Only = ~ absPF ) %>%
  tibble(formulas = .) %>%
  mutate(names = names(formulas)) 

#generate k=10 crossfold validated model
models  <- 1:nrow(FormulaDF) %>% map_df(~{
           print(.x)
           form <- as.formula(FormulaDF %>% pull(formulas) %>% .[[.x]])
    set.seed(1)
    ModelInputVars %>%
      filter(Link.Limit != 1e5) %>%
      crossv_kfold(k = 10) %>%
      #The log limit of the model is used to make it more normally distributed
      mutate(model = map(train, ~lm(form, data = .)
                         ),
              Modelname= FormulaDF %>% pull(names) %>% .[[.x]])#,
          #   ) 

})





#create predictions for each edge in the network
predictions <- models %>%
  unnest(map2(model, test, ~ augment(.x, newdata = .y))) %>%
  mutate(.fitted = 10^.fitted) %>%
  left_join(., OverloadType %>% filter(type == "Edge") %>% select(Link = Name, Overloaded)) %>%
  mutate(Overloaded = Overloaded/1e4) %>%
  filter(complete.cases(.))

ModError <- unique(predictions$Modelname) %>% map_df(~{
  predictions <-  predictions %>% filter(Modelname==.x)
  metrics(predictions , Link.Limit, .fitted) %>% select(-.estimator) %>% spread(key = .metric, value = .estimate) %>%
   bind_cols(tibble(MAPE = mean(abs(predictions$.fitted-predictions$Link.Limit)/predictions$Link.Limit))) %>%
    mutate(Modelname = .x,
           FailOnInit = sum(abs(predictions$.fitted) < abs(predictions$PowerFlow)),
           WeightedRMSE = sqrt(sum((predictions$Overloaded*(predictions$Link.Limit-predictions$.fitted))^2)))
  
}) 

alpha_vector <- c(1.05, 1.1, 1.2, 1.5, 2, 3, 5, 7, 10, 15, 20, 50)
#Include the alpha models
ModError <-  alpha_vector %>% map_df(~{
  print(.x)
predictions <- as_data_frame(g) %>%
  mutate(.fitted = PowerFlow*.x) %>%
  left_join(., OverloadType %>% filter(type == "Edge") %>% select(Link = Name, Overloaded), by = "Link") %>%
  mutate(Overloaded = Overloaded/1e4) %>%
  filter(complete.cases(.))

  metrics(predictions , Link.Limit, .fitted) %>% select(-.estimator) %>% spread(key = .metric, value = .estimate) %>%
   bind_cols(tibble(MAPE = mean(abs(predictions$.fitted-predictions$Link.Limit)/predictions$Link.Limit))) %>%
    mutate(Modelname = paste0("alpha_value_",.x*100),
           FailOnInit = sum(abs(predictions$.fitted) < abs(predictions$PowerFlow)),
           WeightedRMSE = sqrt(sum((predictions$Overloaded*(predictions$Link.Limit-predictions$.fitted))^2)))
}) %>%
  bind_rows(ModError) %>%
  CleanNames(., TargetColumn = "Modelname", AlphaOrder)



```


##This section compares line modell accruacy and collapse model accuracy
```{r}
AlphaOrder <- c("alpha value 1","alpha value 1.05","alpha value 1.1","alpha value 1.2","alpha value 1.5","alpha value 2" ,"alpha value 3","alpha value 5","alpha value 6","alpha value 7","alpha value 10","alpha value 15","alpha value 20","alpha value 50","Topological" ,"PF Model", "Volt PF Model")  

DamageComp <- list.files(path = file.path("/media/jonno/Seagate Expansion Drive/ProportionalLoading",
                                          "SummaryData"), 
                              pattern = ".rds", 
                              full.names = TRUE) %>%
   map_df(~read_rds(.x)) %>%
  mutate(GCfract = ifelse(is.finite(GCfract), GCfract, 1)) %>%
  DamageComparison(., "Blackout", AlphaOrder) %>%
  select(-SimulationID,-alpha) %>%
  group_by(alpha2) %>%
  summarise_all(funs(mean, median)) %>%
  arrange(RMSE_mean) %>%
  select(alpha = alpha2, contains("mean")) %>%
  mutate(alpha = gsub("Model ", "", alpha))%>%
  left_join(ModError, ., by = c("Modelname2"="alpha"))


#The most accurate model in terms of collapse behaviour also has 1 of the lowest Line limit errors
DamageComp %>%
  filter(grepl("alpha", Modelname)) %>%
  mutate(Modelname = gsub("alpha_value_", "", Modelname) %>% as.numeric %>%{./100}) %>%
  ggplot(aes(x = rmse, y = RMSE_mean, colour = Modelname)) + geom_point() +
    AlphaGrad

#I think that I need to run each model as an individual variable and as a pair
#makes 15 models overall
DamageComp %>%
  filter(!grepl("alpha", Modelname)) %>%
  ggplot(aes(x = rmse, y = RMSE_mean, colour = Modelname)) + geom_point() 

DamageComp %>%
    filter(!grepl("alpha", Modelname)) %>%
  ggplot(aes(x = WeightedRMSE, y =RMSE_mean, colour = Modelname )) + geom_point()

```

#Round removed is there a difference?


Do some nodes/edges get targeted later or fail early is there a pattern?
```{r}



testrank <- list.files(Deletion_Order_Folder, 
           pattern = "RandomAttack_", 
           full.names = TRUE) %>%
  map_df(~{
    print(.x)
    list.files(.x, full.names = T) %>%
      map_df(~{
        readRDS(.x)
      })
    
  })


testrank2 <- testrank %>%
  group_by(Name, RemovalType, type) %>%
  summarise(mean = mean(RoundRemoved),
            median = median(RoundRemoved),
            sd = sd(RoundRemoved),
            counts = n())

OveralFailurePoint <- testrank %>%
  group_by(Name, type) %>%
  summarise(Totmean = mean(RoundRemoved),
            Totmedian = median(RoundRemoved),
            Totsd = sd(RoundRemoved)) %>%
  left_join(as_data_frame(g) %>%
  select(Name = Link, from, to), by = "Name"
) %>%
  mutate(from = ifelse(is.na(from), Name, from),
         to = ifelse(is.na(to), Name, to))



VertexMetaData2 <- VertexMetaData %>%
  mutate(NodeType = case_when(
    BalencedPower>0 ~"Generator",
    BalencedPower< 0~"Demand",
    TRUE ~ "Transfer"
  ),
  NodeType2 = case_when(
    Demand>0 & Generation>0 ~"Hybrid",
    TRUE ~ NodeType
  )) %>% select(Name, NodeType, NodeType2, BalencedPower)

VertexMetaData2 %>%
  group_by(NodeType) %>%
  summarise(count = n())

VertexMetaData2 %>%
  group_by(NodeType2) %>%
  summarise(count = n())


 OverloadType %>%
    gather(key = RemovalType, value = value, -Name, -type) %>%
  left_join(OveralFailurePoint) %>%
   mutate(value = value/1e4) %>%
   filter(value !=0, type == "Node") %>% 
   left_join(VertexMetaData2) %>%
  ggplot(aes(x = Totmean, y = value, colour = NodeType2)) + geom_point() +
  facet_grid(~ RemovalType)
 
 
  OveralFailurePoint <- OverloadType %>%
    gather(key = RemovalType, value = value, -Name, -type) %>%
  left_join(OveralFailurePoint) %>%
   mutate(value = value/1e4) %>%
   left_join(VertexMetaData2 %>% select(Name, NodeTypefrom = NodeType2), by = c("from"="Name")) %>%
   left_join(VertexMetaData2 %>% select(Name, NodeTypeto = NodeType2), by = c("to"="Name")) %>%
    mutate(NodeType = case_when(
      NodeTypefrom == NodeTypeto ~ NodeTypefrom,
      NodeTypefrom =="Transfer" ~NodeTypeto,
      NodeTypeto =="Transfer" ~ NodeTypefrom,
      TRUE ~ "Hybrid"
    )) 
  
  OveralFailurePoint %>%
    filter(RemovalType=="Targeted") %>%
    group_by(type, NodeType) %>%
    summarise(counts = n())%>%
    spread(key = type, value = counts)
  
  OveralFailurePoint %>%
      ggplot(aes(x = Totmean, y = value, colour = NodeType)) + geom_point() +
  facet_grid(type~ RemovalType)
 
  OveralFailurePoint %>%
    ggplot(aes(x = NodeType, y = Totmean, fill = NodeType)) +
    geom_boxplot() +
    facet_grid(type ~RemovalType)+
    theme(axis.text.x = element_blank())


testrank2 %>%
  ggplot(aes( x = mean, colour = RemovalType)) + 
  geom_density() +
  facet_wrap(~type)

#Islanding occurs early and with a lower standard deviation, this is unsurprising as it is when the power demand is high and so lines are more likely to overload.
#Targeting averages slightly later than the overloads, this is also expected as on average a line should be targeted in the middle of the attack.
#islanding tends to occur later when the grid is fracturing. The standard deviation decreases the later the mean becomes as there is less ooptions to fail.
#What other information do I need to know if nodes fail early or late?
testrank2 %>%
  ggplot(aes(x = mean, y = sd, colour = RemovalType)) + 
  geom_point() +
  facet_wrap(~type) +
  labs(title = "Failure time for each Node and Edge across all failure modes", colour = "type") 
ggsave("AllFailureModesMeanTimePoint.pdf")



testrank3 <- testrank %>% 
  mutate(Rtype2 = ifelse(RemovalType == "Targeted", "Targeted", "Not Targeted" )) %>%
  group_by(Name, Rtype2, type) %>%
  summarise(mean = mean(RoundRemoved),
            median = median(RoundRemoved),
            sd = sd(RoundRemoved))


DominantFailureMode <- testrank2 %>%
  arrange(-counts) %>%
  group_by(Name, type) %>%
  summarise(DominantType = first(RemovalType)) %>%
  mutate(DominantType2 = ifelse(DominantType=="Targeted", "Targeted", "Not Targeted")) %>%
  left_join(., 
            testrank2 %>%
  arrange(-counts) %>%
  filter(RemovalType != "Targeted") %>%
  group_by(Name, type) %>%
  summarise(DominantType3 = first(RemovalType)) 
  )
  
  




table(DominantFailureMode$DominantType, DominantFailureMode$type)

#Nodes that are prone to islanding are on average targeted earlier becuase otherwise they have failed. Nodes that are not prone to islanding  are on average targeted later as they are usually the only ones left.
#Edges that Overload all do so early but are targeted across most of the span. Edges that are islanded are similar to nodes. Edges that are targeted dominate as a single Node can cause the loss of a large number of edges.
#This might just show that nodes that have power failure later... which is hardly a revelation
testrank3 %>%
  select(-median, -sd) %>%
  spread(Rtype2, mean) %>%
   left_join(DominantFailureMode, by = c("Name", "type")) %>%
  ggplot(aes(x = Targeted, y = `Not Targeted`, colour = DominantType2))  + 
    facet_wrap(~type)+
  geom_point() + 
  labs(title = "Dominant Failure type By time removed", colour = "type")
ggsave(file.path(FiguresFolder, "DominantTypeTimeRemoved.pdf"))



testrank2 %>%
  select(-median, -sd, -counts) %>%
  filter(RemovalType !="Targeted") %>%
  spread(RemovalType, mean, fill = 0) %>%
   left_join(DominantFailureMode, by = c("Name", "type")) %>%
  ggplot(aes(x = Islanded, y = Overloaded, colour = DominantType3))  + 
    facet_wrap(~type)+
  geom_point()


 MetricMap %>%
   filter(metric == "Centrality") %>%
  left_join(DominantFailureMode %>% select(-type), by = c("Link"="Name")) %>%
  filter(!is.na(value)) %>%
  group_by(metric) %>%
  mutate(rank = ntile(value, 100)) %>%
  ungroup %>%
    ggplot(aes(x = Latitude, y = Longitude)) + 
  geom_line(aes(colour = DominantType3, group = Link)) + 
   facet_grid(~PositionType)+
   labs(title= " Dominant Failure type ignoring targeted", colours= "Dominant failure type")
ggsave(file.path(FiguresFolder, "NonDominantFailureType.pdf"))

```


#Get change in failure metrics from and attack
```{r}

#testAttack <- readRDS(file.path("/media/jonno/Seagate Expansion Drive/ProportionalLoading/Saved_Sims/Real_Limits",
#                                "Simulation_ID_19.rds"))

HowmanyOver <- testrank %>% #%>% filter(RemovalType=="Overloaded")
  filter(type == "Edge") %>%
  group_by(Sim) %>%
  mutate(TotalRound = max(RoundRemoved, na.rm = T)) %>%
  group_by(RemovalType, Sim) %>%
  summarise(counts = n(),
            TotalRound = first(TotalRound),
            sd = sd(RoundRemoved)) %>%
  ungroup

#On average 74% of edges are lost to targeting.
HowmanyOver %>%
  group_by(RemovalType) %>%
  summarise(max = max(counts),
            min = min(counts),
            mean = mean(counts),
            median = median(counts))
  
HowmanyOver %>%
  ggplot(aes(x = counts)) + geom_density() + 
  facet_grid(~RemovalType, scales = "free_x")

HowmanyOver %>%
  ggplot(aes(x = TotalRound, y = counts, color = RemovalType )) +
  geom_point()

HowmanyOver %>%
  spread(RemovalType, counts) %>%
  select(-Sim) %>%
  cor(., method = "spearman")

#Overloads happend much closer together than islanding or targeting.
#islanding is a linear process
#Overloading occurs at a similar, point, poss becuase 
HowmanyOver %>%
  ggplot(aes(x = RemovalType, y = sd)) + geom_boxplot()



```

#Simultaneous failure
```{r}

if(!file.exists(file.path(PLwd, "SimultaneousFail.rds"))){

  SimultaneousFail <-unique(testrank$Sim) %>%
    map_df(~{
  print(.x)
  test <- testrank %>%
    filter(type == "Edge", Sim == .x)
  
    test2 <- test %>%
    select( RoundRemoved)%>% 
    as.matrix() 
  rownames(test2) <-test$Name
  
  test2 %>% dist %>% as.matrix() %>% as.tibble %>%
    mutate(Edge1 = names(.)) %>%
    gather(key = Edge2, value = FailDistance, - Edge1) %>%
    filter(Edge1!=Edge2, FailDistance == 0)
  }) %>%
    group_by(Edge1, Edge2) %>%
    summarise(counts = n()) %>%
    mutate(Perc = counts/1e4)
  
  saveRDS(SimultaneousFail, file.path(PLwd, "SimultaneousFail.rds"))

} else{
  
  SimultaneousFail <- readRDS(file.path(PLwd, "SimultaneousFail.rds"))
}



#I am only interested in edges that do not share a common node
#This has Annoying doubles
test <- str_split(SimultaneousFail$Edge2, pattern = "-", simplify = T) %>%
  as.tibble() %>% rename(E2from = V1, E2to = V2) %>%
  bind_cols(str_split(SimultaneousFail$Edge1, pattern = "-", simplify = T) %>%
  as.tibble() %>% rename(E1from = V1, E1to = V2) ) %>%
  mutate(Edge3 = paste(E2from,E2to, sep = "-")) %>%
  bind_cols(SimultaneousFail,.) %>%
#  mutate(Edg12 = Edge2, Edge21 = Edge1) %>%
  left_join(., OverloadType %>% select(-type), by = c("Edge1"="Name")) %>%
  left_join(., OverloadType %>% select(-type), by = c("Edge2"="Name")) %>%
  filter(E1from != E2from, E1from != E2to, E1to !=E2from, E1to != E2to) %>%
  ungroup


gdist <-distances(g, weights = NA) 
gdist <- gdist %>% as_tibble %>%
  mutate(Nodes1 = rownames(gdist)) %>%
  gather(key = Nodes2, value = distance, -Nodes1)

MinDist <- test %>%
select(E2from:E1to) %>%
  left_join(gdist, by = c("E1from"="Nodes1", "E2from" = "Nodes2" )) %>%
  left_join(gdist, by = c("E1from"="Nodes1", "E2to" = "Nodes2" )) %>%
  left_join(gdist, by = c("E1to"="Nodes1", "E2from" = "Nodes2" )) %>%
  left_join(gdist, by = c("E1to"="Nodes1", "E2to" = "Nodes2" )) %>%
  rowwise() %>%
  mutate(distance = min(distance.x, distance.y, distance.x.x, distance.y.y))

test <- test %>%
  bind_cols(., MinDist %>% select(distance))


MaxJointFailProb <- bind_rows(test %>% select(Link = Edge1, Perc, counts, distance), 
          test %>% select(Link = Edge2, Perc, counts, distance)) %>%
  group_by(Link) %>%
  arrange(-Perc) %>%
    summarise(Perc = first(Perc),
            counts = first(counts),
            distance = first(distance)) %>%
  left_join(OverloadType, by = c("Link" = "Name"))

#This is obvious becuase generally the more a node is targeted the less it is failing with other nodes
MaxJointFailProb %>%
  ggplot(aes(x = Targeted, y = Perc)) + geom_point()
cor(MaxJointFailProb$Targeted, MaxJointFailProb$Perc, method = "spearman")

#The London region is by far the most sensitive to joint failure
MakeMapDF(g, read_csv(file.path(basewd, "point.csv")))  %>%
  left_join(MaxJointFailProb, by = c("Link")) %>%
  filter(!is.na(Perc)) %>%
    ggplot(aes(x = Latitude, y = Longitude)) + 
  geom_line(aes(colour = Perc, group = Link), size=0.8) + 
   facet_grid(~PositionType) + 
  #scale_colour_gradient2(low = "#8C510A",mid = "#F5F5F5", high = "#01665e", midpoint = 0.3)
  scale_color_viridis_c()+
  ggtitle("Line maximum joint failure probability for Line pairs that do not share a Node")

```


#High dimensional distance
These results are very similar to the joint failure results
```{r}
EucDist <- testrank %>%
  filter(type == "Edge") %>%
  select(Name, RoundRemoved, Sim) %>%
  spread(key = Sim, value = RoundRemoved) 

temp <- EucDist %>%
  dist()


test <- temp %>% as.matrix() 
colnames(test) <- EucDist$Name
test <- test %>% as.tibble %>% mutate(Edge1 = EucDist$Name) %>%
  gather(key = Edge2, value = FailDistance, - Edge1) %>%
  filter(Edge1!=Edge2)
  
 test <- str_split(test$Edge2, pattern = "-", simplify = T) %>%
  as.tibble() %>% rename(E2from = V1, E2to = V2) %>%
  bind_cols(str_split(test$Edge1, pattern = "-", simplify = T) %>%
  as.tibble() %>% rename(E1from = V1, E1to = V2) ) %>%
  mutate(Edge3 = paste(E2from,E2to, sep = "-")) %>%
  bind_cols(test,.) %>%
  filter(E1from != E2from, E1from != E2to, E1to !=E2from, E1to != E2to)
 
 rm(temp)
 
 
 MinJointFailDist <- bind_rows(test %>% select(Link = Edge1, FailDistance), 
          test %>% select(Link = Edge2, FailDistance)) %>%
  group_by(Link) %>%
  arrange(FailDistance) %>%
    summarise(FailDistance = first(FailDistance)
              ) %>%
  left_join(OverloadType, by = c("Link" = "Name"))

MakeMapDF(g, read_csv(file.path(basewd, "point.csv")))  %>%
  left_join(MinJointFailDist, by = c("Link")) %>%
  filter(!is.na(FailDistance)) %>%
    ggplot(aes(x = Latitude, y = Longitude)) + 
  geom_line(aes(colour = FailDistance, group = Link), size = 0.8) + 
   facet_grid(~PositionType) + 
  #scale_colour_gradient2(low = "#8C510A",mid = "#F5F5F5", high = "#01665e", midpoint = 0.3)
  scale_color_viridis_c()+
  ggtitle("Line maximum joint failure probability for Line pairs that do not share a Node")


#Very high corellation it doesn't matter which one you use
left_join(MaxJointFailProb, MinJointFailDist) %>%
  select(Perc, FailDistance) %>%
cor(method = "spearman")

left_join(MaxJointFailProb, MinJointFailDist) %>%
  ggplot(aes(x = Perc, y = FailDistance)) + geom_point()

```


#Node Simu Fail

the probabiity of two nodes failing at the same time
```{r}
if(exists(file.path(PLwd, "SimultaneousNodeFail.rds"))){
  SimultaneousNodeFail <-1:1e4 %>%
    map_df(~{
  print(.x)
  test <- testrank %>%
    filter(type == "Node", Sim == unique(testrank$Sim)[.x])
  
    test2 <- test %>%
    select( RoundRemoved)%>% 
    as.matrix() 
  rownames(test2) <-test$Name
  
  test2 %>% dist %>% as.matrix() %>% as.tibble %>%
    mutate(Node1 = names(.)) %>%
    gather(key = Node2, value = FailDistance, - Edge1) %>%
    filter(Node!=Node2, FailDistance == 0)
  })%>%
    group_by(Node1, Node2) %>%
    summarise(counts = n()) %>%
    mutate(Perc = counts/1e4) %>%
    ungroup
  saveRDS(SimultaneousNodeFail, file.path(PLwd, "SimultaneousNodeFail.rds"))
} else {
  
  SimultaneousNodeFail <- readRDS( file.path(PLwd, "SimultaneousNodeFail.rds"))
}


MaxJointFailProbNode <- SimultaneousNodeFail %>% select(Node = Node1, counts, Perc) %>%
  bind_rows( SimultaneousNodeFail %>% select(Node = Node2, counts, Perc)) %>%
  group_by(Node) %>%
  summarise(counts = max(counts),
            Perc = max(Perc)) %>%
  left_join(OverloadType, by = c("Node" = "Name"))

MaxJointFailProbNode %>%
  select(Perc, Islanded:Targeted) %>%
  cor

#Very strong Node joint failure
MakeMapDF(g, read_csv(file.path(basewd, "point.csv")))  %>%
  left_join(MaxJointFailProbNode, by = c("Node")) %>%
  filter(!is.na(Perc)) %>%
    ggplot(aes(x = Latitude, y = Longitude)) + 
  geom_line(aes(group = Link), size = 0.8) + 
  geom_point(aes(colour =Perc)) +
   facet_grid(~PositionType) + 
  #scale_colour_gradient2(low = "#8C510A",mid = "#F5F5F5", high = "#01665e", midpoint = 0.3)
  scale_color_viridis_c()+
  ggtitle("Node maximum joint failure probability")

```


#Node influence

The amount of nodes a node takes out on average -done
The number of edges that are overloaded by a node -done
The total amount of power loss caused by a anode

```{r}

AttackRoundData <- list.files("/home/jonno/Dropbox/AWS_Simulation_Files/SummaryData", full.names = TRUE) %>% map_df(~{
    print(.x)

        readRDS(.x)

    
  })


PowerLossDF <-AttackRoundData  %>%
  rename(Sim = simulationID, RoundRemoved = NodesAttacked) %>%
  mutate(Sim = paste0("Simulation_ID_", Sim)) %>%
  group_by(Sim) %>%
  mutate(PowerGenTM1 = lag(PowerGen),
         PowerChange = PowerGen-PowerGenTM1) %>%
  ungroup %>%
  select(Sim, RoundRemoved, PowerChange)

NodesLost <- testrank %>%
  filter(RemovalType !="Targeted", type =="Node") %>%
  group_by(RoundRemoved, Sim) %>% 
  summarise(NodesLost = n())


EdgeLoss<- testrank %>%
  filter(RemovalType =="Overloaded", type =="Edge") %>%
  group_by(RoundRemoved, Sim) %>% 
  summarise(EdgesOverload = n())

test2 <- testrank %>%
   filter(RemovalType =="Targeted", type =="Node") %>%
  select(-type, -RemovalType) %>%
  left_join(NodesLost) %>%
  left_join(EdgeLoss)  %>%
  left_join(PowerLossDF) #Something wierd is going on with power loss. I need to take a closer look at the attack round data
 #left_join(VertexMetaData %>% select(Name, BalencedPower)) %>%# these results are just wierd
  #mutate(AdjPowerLoss = PowerLoss - abs(BalencedPower))

InfluentialNodes <- testrank %>%
   filter(RemovalType =="Targeted", type =="Node") %>%
  select(-type, -RemovalType) %>%
  left_join(NodesLost) %>%
  left_join(EdgeLoss) %>%
  left_join(PowerLossDF) %>%
  group_by(Name) %>%
  summarise(MeanNodes = mean(NodesLost, na.rm = TRUE),
            MedianNodes = median(NodesLost, na.rm = T),
            NodesAllSims = sum(NodesLost, na.rm = T)/1e4,
            sdNodes = sd(NodesLost, na.rm = T),
            NodeOccs = sum(!is.na(NodesLost)),
            MeanEdgesOverloaded = mean(EdgesOverload, na.rm = T),
            MedianEdgesOverloaded = median(EdgesOverload, na.rm = T),
            sdEdgesOverloaded = sd(EdgesOverload, na.rm = T),
            EdgeOccs = sum(!is.na(EdgesOverload)),
            MeanPowerChange = mean(PowerChange, na.rm = T),
            MedianPowerChange = median(PowerChange, na.rm = T),
            sdPowerChange = sd(PowerChange, na.rm = T)) %>%
  left_join(MaxJointFailProbNode %>% select(Name = Node, Perc)) %>%
  left_join(VertexMetaData2)


#Doesn't show any difference betweeen types.
#Again suggests that e-topology is the important thing.
InfluentialNodes %>%
  ggplot(aes(x  = MeanNodes, color = NodeType2)) + geom_density()

InfluentialNodesEUC <- InfluentialNodes %>%
    #filter(NodeOccs>100) %>%
  mutate(DamagePercentile = percent_rank(MeanNodes),
         ConsistantPercentile = percent_rank(NodesAllSims),
         DamagePercentile = ifelse(NodeOccs<100, 0, DamagePercentile), #Comment out if not wanted
         ConsistantPercentile = ifelse(NodeOccs<100, 0, ConsistantPercentile), #Comment out if not wanted
         Class = case_when(
           DamagePercentile > 0.5 & ConsistantPercentile > 0.5 ~"Leader",
                      DamagePercentile < 0.5 & ConsistantPercentile < 0.5 ~"Follower",
                      DamagePercentile > 0.5 & ConsistantPercentile < 0.5 ~"Blackswan",
           TRUE ~ "Consistant"
         ),
         NodeInfluence = (MeanNodes*NodesAllSims),
         #NodeInfluence = sqrt(MeanNodes^2 + NodesAllSims^2),
         NodeInfluencePerc = percent_rank(NodeInfluence)) 

InfluentialNodesEUC %>%
  filter(NodeOccs>100) %>%
  ggplot(aes(x = MeanNodes, y = NodesAllSims, colour = Class)) +
  geom_point() +
  labs(title= "The influence class of each node")
#Try again when ggnewscale is updated
# + geom_point(aes(colour = DamagePercentile), alpha = 0.5)+
#   scale_color_gradient(low = "white", high = "blue")+
#   new_scale_color() + 
#   geom_point(aes(colour = DamagePercentile), alpha = 0.5)+
#   scale_color_gradient(low = "white", high = "red")

#nice seeds
#7892 256

#remove low occs?
g %>%
  set.edge.attribute(., "weight", value = get.edge.attribute(., "Y")) %>%
MakeMapDF(., read_csv(file.path(basewd, "point.csv")), 7892)  %>%
  left_join(InfluentialNodesEUC, by = c("Node"="Name")) %>%
  filter(!is.na(Perc)) %>%
    ggplot(aes(x = Latitude, y = Longitude)) + 
  geom_line(aes(group = Link), size = 0.8) + 
  geom_point(aes(colour =NodeInfluencePerc ))+
  #geom_point(data = . %>%filter(NodeInfluencePerc>0.9), aes(colour =NodeType )) +
  scale_color_viridis_c()+
  facet_grid(~PositionType) 


InfluentialNodes2 <- InfluentialNodes %>%
  rename(target = EdgeOccs) %>%
  mutate(MedianEdgesOverloaded = ifelse(target<100, NA, MedianEdgesOverloaded))



InfluentialNodes2 %>%
  ggplot(aes(x = MeanNodes, y = MeanEdgesOverloaded, color = Perc)) + geom_point()


MapDFInfluence <- MakeMapDF(g, read_csv(file.path(basewd, "point.csv")))  %>%
  left_join(InfluentialNodes2, by = c("Node"="Name"))

#Seldom targeted nodes are removed as they are just noise
MapDFInfluence %>%
  filter(!is.na(Perc)) %>%
#  select(Latitude, Longitude, Link, MedianNodes, MedianEdgesOverloaded, PositionType) #get overloads and nodes removed in same plot
    ggplot(aes(x = Latitude, y = Longitude)) + 
  geom_line(aes(group = Link), size = 0.8) + 
  geom_point(data = MapDFInfluence %>% filter(target>100), aes(colour =ntile(MedianEdgesOverloaded, 100) )) +
   facet_grid(~PositionType) + 
  #scale_colour_gradient2(low = "#8C510A",mid = "#F5F5F5", high = "#01665e", midpoint = 0.3)
  scale_color_viridis_c()+
  labs(title = "Most Influential Nodes at overloading coloured by percentile rank", colour = "Percentile")
ggsave(file.path(FiguresFolder, "OverloadPercRank.pdf"))

#Attacks around london and the northern cities reduce power
#But attacks around scotland increase power... whats that about?
MakeMapDF(g, read_csv(file.path(basewd, "point.csv")))  %>%
  left_join(InfluentialNodes, by = c("Node"="Name")) %>%
  filter(!is.na(Perc)) %>%
    ggplot(aes(x = Latitude, y = Longitude)) + 
  geom_line(aes(group = Link), size = 0.8) + 
  geom_point(aes(colour =ntile(abs(MeanPowerChange), 10) )) +
   facet_grid(~PositionType) + 
  #scale_colour_gradient2(low = "#8C510A",mid = "#F5F5F5", high = "#01665e", midpoint = 0.3)
  scale_color_viridis_c()+
  labs(title = "Causes power change to grid on Removal", colour = "Percentile")


#Rank Influence metrics from 1 to 100 and find the euclidean dsitance from 0
MultiInfluence <- InfluentialNodes %>%
  ##Turn any nodes below the 1% threshold to zero
  mutate(MedianNodes = ifelse(NodeOccs<100, 0, MedianNodes),
         MedianPowerChange = ifelse(NodeOccs<100, 0, MedianPowerChange),
         MedianEdgesOverloaded = ifelse(EdgeOccs<100, 0, MedianEdgesOverloaded)) %>%
  select(Name, MedianNodes, MedianEdgesOverloaded, MedianPowerChange, NodeOccs) %>%
  mutate(MedianPowerChange = abs(MedianPowerChange)) %>%
  mutate_if(is.numeric, percent_rank) %>%
  mutate(Dist = (MedianNodes^2+MedianEdgesOverloaded^2+MedianPowerChange^2)^(1/3),
         PercMax = Dist/max(Dist),
         Dist2 = sqrt(Dist^2+(NodeOccs/1e4)^2), #adjusting for amount of occurances.. basically not a lot of difference
         Dist3 = Dist*(NodeOccs/1e4),
         PercMax2 = Dist3/max(Dist3)) %>% # slightly more distrance here
  left_join(VertexMetaData2)

cor(select(MultiInfluence, Dist, Dist2, Dist3))

#Hybrid nodes are most influential
MultiInfluence %>%
  ggplot(aes(x = NodeType2, y = PercMax)) + geom_boxplot()

MakeMapDF(g, read_csv(file.path(basewd, "point.csv")))  %>%
  left_join(MultiInfluence, by = c("Node"="Name")) %>%
  filter(!is.na(PercMax)) %>%
    ggplot(aes(x = Latitude, y = Longitude)) + 
  geom_line(aes(group = Link), size = 0.8) + 
  geom_point(aes(colour =PercMax)) +
   facet_grid(~PositionType) + 
  #scale_colour_gradient2(low = "#8C510A",mid = "#F5F5F5", high = "#01665e", midpoint = 0.3)
  scale_color_viridis_c() +
  ggtitle("Combined influence metrics as a percentage of maximum")

#Most nodes are of similar importance, a few nodes are very important
#A substantial number of nodes are of very little importances generally.
MultiInfluence %>%
  ggplot(aes(x = PercMax)) + geom_density() +
  labs(title = "Combined influence density plot")

table(MultiInfluence$PercMax==0)

```


##Differnce in co-failure between Targeted/Islanded type Nodes

```{r}
NodeMeanFailProb <- SimultaneousNodeFail %>%
  select(-Perc) %>%
  spread(key = Node2, value = counts, fill = 0) %>%
  gather(key = Node2, value = counts, -Node1) %>%
  rename(Name = Node1) %>%
    group_by(Name) %>%
  summarise(mean = mean(counts),
            max = max(counts)) %>%
  mutate(Perc = mean/1e4) %>%
  left_join(DominantFailureMode)


EdgeMeanFailProb <- SimultaneousFail %>%
  select(-Perc) %>%
  spread(key = Edge2, value = counts, fill = 0) %>%
  gather(key = Edge2, value = counts, -Edge1) %>%
  rename(Name = Edge1) %>%
    group_by(Name) %>%
  summarise(mean = mean(counts),
            max = max(counts)) %>%
  ungroup %>%
  mutate(Perc = mean/1e4) %>%
  left_join(DominantFailureMode)


bind_rows(NodeMeanFailProb, EdgeMeanFailProb) %>%
  ggplot(aes(x = Perc, colour = type)) + geom_density()

#Nodes who generally fail through islanding or overload have a significantly higher mean probability of failure with other nodes
#They also have a higher maximum join probability of failure than nodes that are removed through targeting
bind_rows(NodeMeanFailProb, EdgeMeanFailProb)  %>%
  ggplot(aes(x = DominantType2, y = Perc, fill = DominantType2)) +geom_boxplot()+
  facet_grid(~type)+
  labs(title = "Mean joint failure probability", x ="Failure mode", y = "Mean probability of joint failure with all other nodes/edges")
ggsave(file.path(FiguresFolder,"JointMeanFail.pdf"))
  

GreaterThanX <- seq(0.1,0.8, 0.1) %>%
  map_df(~{
    
    SimultaneousNodeFail %>%
      mutate(Geq = Perc>.x) %>%
      group_by(Node1) %>%
      summarise(Geq = sum(Geq)) %>%
      ungroup %>%
      mutate(Perc = .x)
  }) %>%
  left_join(DominantFailureMode, by = c("Node1"= "Name")) %>%
  group_by(Perc, DominantType2) %>%
  summarise(mean = mean(Geq))

GreaterThanX %>%
  ggplot(aes(x = Perc, y = mean, colour = DominantType2)) + geom_line() +
  labs(title = "Difference between average number of nodes with at least join failure probability")
ggsave(file.path(FiguresFolder, "GreaterThanx.pdf"))



#Previosuly this showed the split between islanding and overloading now we show it in terms of mean joint failure probability
#Higher joint probability means earlier removal as it has to be removed early or it will fail.
testrank3 %>%
  select(-median, -sd) %>%
  spread(Rtype2, mean) %>%
   left_join(DominantFailureMode, by = c("Name", "type")) %>%
  #filter(type == "Node") %>%
  left_join(bind_rows(NodeMeanFailProb, EdgeMeanFailProb)%>% select(Name, Perc, type) , by = c("Name", "type")) %>%
 # left_join(VertexMetaData2) %>% filter(type == "Node") %>%
  group_by(type) %>%
  mutate(PercRank = percent_rank(Perc)) %>%
  ggplot(aes(x = Targeted, y = `Not Targeted`, colour = PercRank))  + 
 #   facet_wrap(~(Perc>0.01))+
  facet_grid(~type)+
  geom_point() +
  #geom_point(aes(shape = NodeType2), size = 3)+
   scale_color_viridis_c()

testrank3 %>%
  select(-median, -sd) %>%
  spread(Rtype2, mean) %>%
   left_join(DominantFailureMode, by = c("Name", "type")) %>%
  #filter(type == "Node") %>%
  left_join(MultiInfluence, by = c("Name")) %>%
 filter(type == "Node") %>%
  ggplot(aes(x = Targeted, y = `Not Targeted`, colour = PercMax))  + 
  geom_point()+
   scale_color_viridis_c()


testrank3 %>%
  select(-median, -sd) %>%
  spread(Rtype2, mean) %>%
   left_join(DominantFailureMode, by = c("Name", "type")) %>%
  #filter(type == "Node") %>%
  left_join(MultiInfluence, by = c("Name")) %>%
 filter(type == "Node") %>%
  ggplot(aes(x =PercMax, colour = DominantType2))  + 
  geom_density()


```

#Co-failure graph

##functions
```{r}
#The brackets just ensure all the code is run at once
MakeNodeCommunity <-function(JointFailureProbg){
  NodeCommunity <-tibble(Node = JointFailureProbg$names, membership = JointFailureProbg$membership) 

CommunityRank <-NodeCommunity %>%
  group_by(membership) %>%
  summarise(size = n()) %>%
  ungroup %>%
   mutate(rank = rank(-size, ties.method = "random"))

NodeCommunity %>%
  left_join(CommunityRank) %>%
  mutate( Community = case_when(
      size>=20 ~ as.character(rank),
      size>=10 ~ "medium",
      TRUE ~ "small"
    ),
     Community2 = case_when(
      size<20 & size>=10~ as.character(rank),
      size>=20 ~ "Large",
      TRUE ~ "small"
    ))
}


IsSameCommunity <-function(Community1, Community2){
  #uses the output of Make Node Community to find if two nodes share the same community using the different methods
  
  testmat <- matrix(rep(Community1 %>% pull(membership), nrow(Community1)),
         ncol=nrow(Community1),
         byrow=T)

testmat2 <- matrix(rep(Community2 %>% pull(membership), nrow(Community2)),
         ncol=nrow(Community2),
         byrow=F)

testmat3 <- testmat == testmat2
#diag(testmat3) <- FALSE

as_tibble(testmat3) %>%
  set_names(Community1$Node) %>%
  mutate(Node2 = Community2$Node) %>%
  gather(key = Node1, value = SameFailureGroup, -Node2)
}


CommunityAdjacencyMat<- function(Community1){
  #Creates a community adjacency matrix, where there is a 1 if nodes are in the same community 
  #and a zero if they are not
  testmat <- matrix(rep(Community1 %>% pull(membership), nrow(Community1)),
         ncol=nrow(Community1),
         byrow=T)

testmat3 <- testmat == t(testmat)
return(testmat3)
  }

IsSameCommunity2 <-function(Community1, Community2){
  #uses the output of Make Node Community to find if two nodes share the same community using the different methods
  
  Community1 <- Community1 %>% full_join(Community2 %>% select(Node)) %>% arrange(Node)
  Community2 <- Community2 %>% full_join(Community1 %>% select(Node)) %>% arrange(Node)
  
    CommAdjMat1 <- CommunityAdjacencyMat(Community1)
    CommAdjMat1[is.na(CommAdjMat1)] <- FALSE
    CommAdjMat2 <- CommunityAdjacencyMat(Community2)
    CommAdjMat2[is.na(CommAdjMat2)] <- FALSE
    
    Jaccard <- 1:ncol(CommAdjMat1) %>% map_dbl(~{
       A <- CommAdjMat1[,.x]
       B <- CommAdjMat2[,.x]
      
      sum(A*B)/(sum(A)+sum(B)-sum(A*B))
    })
    
    tibble(Jaccard = Jaccard, Node = Community1$Node)
    
    
}

  
```

##Creat Graph
```{r}
DistDF <- SimultaneousNodeFail %>%
  mutate(Perc2 = 1-Perc,
    counts2 = 1e4-counts,
         InvCounts = 1/counts)

DistMat0 <- DistDF %>%
  select(Node1, Node2, InvCounts) %>%
  spread(key = Node2, value = InvCounts, fill = 1) 

DistMat <- DistMat0 %>%
  select(-Node1) %>%
  as.matrix()

#Join Failure has no direction
FailureNodeCommunity  <- DistDF %>%
  select(Node1, Node2, weight = counts) %>%
  filter(weight >=1000) %>% #only edges with at least 1000 occurrances aka 10%, I'm not sure on the rights and wrongs of a cut off. This is definately a case for the metric backbone. Doing this or not makes a substantial difference
  graph_from_data_frame(directed = FALSE) %>% cluster_walktrap(.) %>% 
  MakeNodeCommunity()

#The topological community can have the direction that the power flows in aka A to B
TopoNodeCommunity <- as_data_frame(g) %>% as_tibble %>%
  mutate(from2 = ifelse(PowerFlow>0, from, to),
         to2 = ifelse(PowerFlow>0, to, from),
         from = from2,
         to = to2,#this is so confusing I am keeping in the columns to make it easier to check back on
         PowerFlow = abs(PowerFlow)) %>%
   graph_from_data_frame(directed = TRUE) %>% set.edge.attribute(., "weight", value = 1) %>%
cluster_infomap()%>% MakeNodeCommunity()

#Direction in Electrical distance is arguably meaningless as electricty flows over all available paths
#I don't think electrical distance is working. It may be scrambling node names
ElecDistCommunity <- ImpPTDF(g, "FECK")$Imp %>%
  ElectricalDistance() %>%
  as.tibble %>%
  mutate(Node1 = names(.)) %>%
  gather(key= Node2, value = Distance, -Node1) %>%
  filter(Distance != 0) %>%
  mutate(DistPerc = Distance/max(Distance),
         weight = 1/Distance,
         LinkType1 = paste(Node1, Node2, sep ="-"),
         LinkType2 = paste(Node2, Node1, sep ="-")) #%>%
 # filter(LinkType1 %in% get.edge.attribute(g, "name")get.edge.attribute(g, "name")) #totally not helpful


AdmitTopology <- ImpPTDF(g, "CRSS")$Imp %>% solve(.) 

AdmitTopology <- tibble(from = rownames(AdmitTopology)) %>% 
  bind_cols(as_tibble(AdmitTopology)) %>%
  gather(key = to, value = Admittance,-from) %>%
  mutate(Admittance = abs(Admittance)) #This is an utter mess


TopoNodeCommunity2 <- as_data_frame(g) %>% as_tibble %>%
  mutate(from2 = ifelse(PowerFlow>0, from, to),
         to2 = ifelse(PowerFlow>0, to, from),
         from = from2,
         to = to2,#this is so confusing I am keeping in the columns to make it easier to check back on
         PowerFlow = abs(PowerFlow)) %>%
  left_join(AdmitTopology)%>%
  mutate(weight = Admittance) %>%
  group_by(from) %>%
  mutate(weight = weight/sum(weight)) %>%
   graph_from_data_frame(directed = TRUE)  %>%
cluster_walktrap()%>% MakeNodeCommunity()

test <- ElecDistCommunity %>%
  select(Node1, Node2, Distance) %>%
  graph_from_data_frame(directed = FALSE) %>%
cluster_leading_eigen(.) %>% MakeNodeCommunity()

ElecHclust <-ImpPTDF(g, "FECK")$Imp %>%
  ElectricalDistance() %>% dist %>% hclust


{
  Elecmember <- cutree(ElecHclust, k = 20) %>% tibble(Node = names(.), membership = .) 
CommunityRank <- Elecmember %>%
  group_by(membership) %>%
  summarise(size = n()) %>%
  ungroup %>%
   mutate(rank = rank(-size, ties.method = "random"))

Elecmember <- Elecmember%>%
  left_join(CommunityRank) %>%
  mutate( Community = case_when(
      size>=20 ~ as.character(rank),
      size>=10 ~ "medium",
      TRUE ~ "small"
    ),
     Community2 = case_when(
      size<20 & size>=10~ as.character(rank),
      size>=20 ~ "Large",
      TRUE ~ "small"
    ))
  
rm(CommunityRank)
}

ElecDistCommunity %>%
  ggplot(aes(x = weight))+ geom_density()

```

###Failure group map
```{r}
MakeMapDF(g, read_csv(file.path(basewd, "point.csv")))  %>%
  left_join(FailureNodeCommunity) %>%
  left_join(VertexMetaData2 %>% rename(Node = Name)) %>%
  mutate(Community = ifelse(is.na(Community), "small", Community),
         Community2 = ifelse(is.na(Community), "small", Community2)) %>%
 # filter(Community=="2", PositionType == "Geo Space") %>% #Look at individual clusters
    ggplot(aes(x = Latitude, y = Longitude)) + 
  geom_line(aes(group = Link), size = 0.8, arrow = arrow(angle = 15, length= unit(0.3, "cm"), type = "closed")) + 
  geom_point(#data = . %>% filter(Community != "small", Community != "medium"), #Keep only large clusters
             aes(colour =Community, shape = NodeType), size = 2) +
   facet_grid(~PositionType)+
   # scale_color_brewer(type = "qual")
  scale_color_brewer(palette = "Set1") +
  labs(title = "Failure groups")
ggsave(file.path(FiguresFolder, "Failuregroups.pdf"))

test <-  MakeMapDF(g, read_csv(file.path(basewd, "point.csv")))  %>%
  left_join(FailureNodeCommunity) %>%
    mutate(Community = ifelse(is.na(Community), "small", Community),
         Community2 = ifelse(is.na(Community2), "small", Community2)) 

p <- MakeMapDF(g, read_csv(file.path(basewd, "point.csv")))  %>%
  left_join(FailureNodeCommunity) %>%
  left_join(VertexMetaData2 %>% rename(Node = Name)) %>%
  mutate(Community = ifelse(is.na(Community), "small", Community),
         Community2 = ifelse(is.na(Community), "small", Community2)) %>%
 # filter(Community=="2", PositionType == "Geo Space") %>% #Look at individual clusters
    ggplot(aes(x = Latitude, y = Longitude)) + 
  geom_line(aes(group = Link), size = 0.8, arrow = arrow(angle = 15, length= unit(0.3, "cm"), type = "closed")) + 
  geom_point(#data = . %>% filter(Community != "small", Community != "medium"), #Keep only large clusters
             aes(colour =Community, shape = NodeType), size = 2) +
   facet_grid(~PositionType)+
   # scale_color_brewer(type = "qual")
  scale_color_brewer(palette = "Set1") +
  labs(title = "Failure groups")

(gg <- ggplotly(p))

# Scatterplot
p=ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, color=Species, shape=Species)) + 
    geom_point(size=6, alpha=0.6)
p 

	
ggplotly(p)


```


##Aggregated Map
```{r}
#Aggregated Map
test <- MakeMapDF(g, read_csv(file.path(basewd, "point.csv")))  %>%
  left_join(FailureNodeCommunity)

CommMid <- test %>%
  select(Node, Longitude, Latitude, PositionType, membership, size, Community) %>%
  distinct() %>%
  group_by(membership, PositionType) %>%
summarise(Longitude = mean(Longitude),
          Latitude = mean(Latitude),
          size = first(size),
          Community = first(Community)) %>%
  rename(Node = membership)

test2 <- test %>% as.tibble %>%
  filter(type=="to") %>% select(Link, membership2 = membership, to = Node) %>%
  left_join(test %>% filter(type =="from"), .) %>%
  rename(from = Node)

CommEdges <- test2 %>%
  group_by(membership, membership2) %>%
  summarise(counts = n()) %>%
  filter(!is.na(membership), !is.na(membership2), membership!=membership2) %>%
  rename(from = membership, to = membership2) %>%
  mutate(Link = paste0(from, "-", to)) %>%
  gather(key = type, value = Node, -counts,-Link) %>%
  left_join(CommMid)


CommEdges %>%
    ggplot(aes(x = Latitude, y = Longitude)) + 
   geom_line(aes(group = Link), arrow = arrow(angle = 15, length= unit(0.3, "cm"), type = "closed")) + 
  geom_point( aes(size = size, colour = Community)) +
   facet_grid(~PositionType)+
   # scale_color_brewer(type = "qual")
 scale_color_brewer(palette = "Set1") +
  labs(title = "Failure groups")
```



##Compare cluster similarity
```{r}

CommSim <- IsSameCommunity2(FailureNodeCommunity, TopoNodeCommunity) %>%
  left_join(FailureNodeCommunity, by = c("Node"= "Node")) %>%
  group_by(membership) %>%
  summarise(Jaccard = mean(Jaccard),
            size = first(size),
            rank = first(rank),
            Community = first(Community))

CommSim2 <- IsSameCommunity2(test,TopoNodeCommunity) %>%
  left_join(FailureNodeCommunity, by = c("Node"= "Node")) %>%
  group_by(membership) %>%
  summarise(Jaccard = mean(Jaccard),
            size = first(size),
            rank = first(rank),
            Community = first(Community))



#It's a mess
CommSim %>%
  ggplot(aes(x = size, y = Jaccard, colour = Community))+ geom_point() +
   scale_color_brewer(palette = "Set1") 

MakeMapDF(g, read_csv(file.path(basewd, "point.csv")))  %>%
  left_join(FailureNodeCommunity) %>%
  left_join(CommSim2) %>%
  mutate(Community = ifelse(is.na(Community), "small", Community),
         Community2 = ifelse(is.na(Community), "small", Community2)) %>%
    ggplot(aes(x = Latitude, y = Longitude)) + 
  geom_line(aes(group = Link), size = 0.8) + 
  geom_point(aes(colour =Jaccard), size = 2) +
   facet_grid(~PositionType)+
scale_colour_viridis_c()
   
```


#Influence network
Howmany times has node a caused the loss of node B

```{r}
 
TargetNodes <- testrank %>%
  filter(type == "Node", RemovalType=="Targeted") %>%
  select(Node1 = Name, Sim, RoundRemoved)

LostNodes <- testrank %>%
  filter(type == "Node", RemovalType!="Targeted")
  
InfluenceGraphDF <- left_join(LostNodes, TargetNodes, by = c("Sim", "RoundRemoved")) %>%
  rename(Node2 = Name) %>%
  group_by(Node1, Node2) %>%
  summarise(counts = n()) %>%
  mutate(Perc = counts/1e4)

Infg <- InfluenceGraphDF %>%
  select(-counts) %>%
  rename(weight = Perc) %>%
  graph_from_data_frame()


 test <-Infg  %>% cluster_walktrap(.) %>% MakeNodeCommunity(.)

 #These groups are not the same as the cofailure groups..interesting!
 MakeMapDF(g, read_csv(file.path(basewd, "point.csv")))  %>%
  left_join(test) %>%
  mutate(Community = ifelse(is.na(Community), "small", Community),
         Community2 = ifelse(is.na(Community), "small", Community2)) %>%
    ggplot(aes(x = Latitude, y = Longitude)) + 
 # geom_line(aes(group = Link), size = 0.8) + 
#     geom_line(aes(group = Link), size = 0.8, arrow = arrow(angle = 15, length= unit(0.3, "cm"), type = "closed")) + 
  geom_point(aes(colour =Community), size = 2) +
   facet_grid(~PositionType)

test <- left_join(InfluenceGraphDF, InfluenceGraphDF %>% rename(Node1 = Node2, Node2 = Node1), by = c("Node1", "Node2"))



targetnodes <- c("SIZE", "BRFO")

test %>%
  filter(Node1 %in% targetnodes, Node2 %in% targetnodes)

```


#Hierarchical clustering
```{r}
lossdist <- testrank %>% 
  filter(type =="Node") %>%
  select(Name, RoundRemoved, Sim) %>%
  spread(key = Name, value = RoundRemoved)

rownames(lossdist) <- testrank %>% 
  filter(type =="Node") %>%
  select(Name, RoundRemoved, Sim) %>%
  spread(key = Name, value = RoundRemoved) %>% pull(Sim)

lossdist2 <- dist(lossdist %>% select(-Sim))

hclusters <- hclust(lossdist2)

plot(hclusters)


clustdata <- 2500:3067 %>% map_df(~{

  tempclust <- tibble(clusters = cutree(hclusters, h = .x)) %>%
    group_by(clusters) %>%
    summarise(size = n())
  
print(paste("height", .x, " Number of clusters", nrow(tempclust)))
    
  tempclust %>%
    summarise(max = max(size),
              min = min(size),
              mean = mean(size),
              median = median(size),
              sd = sd(size)) %>%
    mutate(Total = nrow(tempclust),
           height = .x)
  
  }
)

clustdata %>%
  filter(height>=1460, height<= 3070) %>%
  ggplot(aes(x = height, y = Total)) + geom_point()
 


clustdatak <- 100:1 %>% map_df(~{
print(.x)
  tempclust <- tibble(clusters = cutree(hclusters, k = .x)) %>%
    group_by(clusters) %>%
    summarise(size = n())
  
  tempclust %>%
    summarise(max = max(size),
              min = min(size),
              mean = mean(size),
              median = median(size),
              sd = sd(size)) %>%
    mutate(Total = nrow(tempclust),
           height = .x)
  
  }
)
Clusts <- 10

cutree(hclusters, k = Clusts) %>% tibble(Clusters = .) %>%
  group_by(Clusters) %>%
  summarise(counts = n()) %>% 
  ungroup %>%
  arrange(-counts) %>%
  mutate(Perc = counts/sum(counts),
         CumSum = cumsum(Perc))

test <- testrank %>%
  filter(type =="Node") %>%
  left_join(tibble(Sim = names(cutree(hclusters, k = Clusts)), 
                   Cluster = cutree(hclusters, k = Clusts)), by = "Sim") %>%#add in simulation groups
left_join(FailureNodeCommunity,  by = c("Name"="Node"))


test2 <- test %>% 
#  filter(RemovalType=="Targeted") %>% #big difference if this is included or not
  group_by(Cluster, membership, Community) %>%
  summarise(MeanRoundRemoved = mean(RoundRemoved),
            MedianRoundRemoved = median(RoundRemoved),
            size = first(size)) %>%
  ungroup

#The mean round removed of each failure group when broken out by simulation cluster
test2 %>%
  mutate(Cluster = factor(Cluster)) %>% 
 #filter(Community!="small", Community!="medium") %>% 
  ggplot(aes(x = MeanRoundRemoved, y = Cluster,fill=Community, size = size)) + 
  geom_point( 
       colour="black",pch=21) +
    scale_fill_brewer(palette = "Set1") 


 test %>%
  filter(Community!="small", Community!="medium") %>%
  group_by(membership, Sim, Community) %>%
  summarise(mean = mean(RoundRemoved)  ) %>%
  ungroup %>% 
  mutate(membership = factor(membership)) %>%
  ggplot(aes(x = membership, y= mean, fill = membership)) + geom_boxplot()

test %>%
  group_by(Cluster, Sim, RemovalType) %>%
  summarise(counts = n()) %>%
  ungroup %>%
  filter(RemovalType!="Targeted") %>%
  #spread(key = RemovalType, value = counts) %>%
  #mutate(ratio = Overloaded/(Islanded+ Overloaded+Targeted)) %>%
  mutate(counts = counts/512) %>%
  mutate(Cluster = factor(Cluster)) %>%
  ggplot(aes(x = Cluster, y = counts, fill = Cluster)) + 
  geom_boxplot() + 
  facet_grid(RemovalType~., scales = "free_y")

test %>%
 group_by(Cluster, Sim) %>%
  summarise(TotalRounds = max(RoundRemoved)) %>%
   ungroup %>%
  mutate(Cluster = factor(Cluster)) %>%
  ggplot(aes(x = Cluster, y = TotalRounds, fill = Cluster)) + 
  geom_boxplot()

#make a classifier
test3 <- InfluentialNodes %>%
  filter(EdgeOccs>1000)


test4 <- test3 %>% select(Sim, membership, MeanRoundRemoved, Cluster) %>%
  filter(!is.na(membership)) %>%
  mutate(membership = make.names(membership)) %>%
  spread(key = membership, value= MeanRoundRemoved)



```

#Messy tree stuff

I am trying to roll up a tree into a simpler form

It is proving difficult.

```{r}


library(ggalluvial)

clustdataKLong <- 100:1 %>% map_df(~{
print(.x)
  tempclust <- tibble(clusters = cutree(hclusters, k = .x), k = .x) %>% 
    bind_cols(lossdist %>% select(Sim))

  }
)


knum <- 20

test <- clustdataKLong %>%
  filter(k <=knum) %>%
  mutate(k = paste0("k", k)) %>%
  spread(key = k, value = clusters) %>%
  group_by(.dots = (paste0("k", 1:knum))) %>%
  summarise(Freq = n()) %>%  
  to_lodes_form(.,
                key = "k",
                axes = 1:knum)


ggplot(data = test,
       aes(x = k, stratum = stratum, alluvium = alluvium,
           y = Freq, label = stratum)) +
  geom_flow(aes(fill = stratum)) +
  geom_stratum() + geom_text(stat = "stratum") 

testphylo <- hclusters %>% as.phylo()

ggtree(testphylo, , layout="circular")


lossdistNode <- testrank %>% 
  filter(type =="Node") %>%
  select(Name, RoundRemoved, Sim) %>%
  spread(key = Sim, value = RoundRemoved)  %>% 
  select(-Name) %>% as.matrix
  

rownames(lossdistNode) <- testrank %>% 
  filter(type =="Node") %>%
  select(Name, RoundRemoved, Sim) %>%
  spread(key = Sim, value = RoundRemoved) %>% pull(Name)

hclustersNode <- lossdistNode %>% dist %>% hclust()

plot(hclustersNode)

clustdataNodes <- seq(14000, 10e3, by = -10) %>% map_df(~{
print(.x)
  tempclust <- tibble(clusters = cutree(hclustersNode, h = .x)) %>%
    group_by(clusters) %>%
    summarise(size = n())
  
  tempclust %>%
    summarise(max = max(size),
              min = min(size),
              mean = mean(size),
              median = median(size),
              sd = sd(size)) %>%
    mutate(Total = nrow(tempclust),
           height = .x)
  
  }
)

clustdatakNodes <- 100:1 %>% map_df(~{
print(.x)
  tempclust <- tibble(clusters = cutree(hclustersNode, k = .x)) %>%
    group_by(clusters) %>%
    summarise(size = n())
  
  tempclust %>%
    summarise(max = max(size),
              min = min(size),
              mean = mean(size),
              median = median(size),
              sd = sd(size)) %>%
    mutate(Total = nrow(tempclust),
           height = .x)
  
  }
)


install.packages("tidytree")

testphylo <- hclustersNode %>% as.phylo 

testphylo%>%
ggtree(. , layout="circular")

ci <- testphylo %>% 
  coalescent.intervals()

set.seed(2017)
tree <- rtree(4)
d <- tibble(label = paste0('t', 1:4),
trait = rnorm(4))
x <- as_tibble(tree)
full_join(x, d, by = 'label') %>% as.treedata

x2 <- testphylo %>% as_tibble() %>%
  mutate(height = node.height(testphylo, clado.style = FALSE))



plot(testphylo)

cutree(testphylo, h = 11550)


offspring(x2, 11550, tiponly = FALSE)

1:6

parentNode <- 513

x2 %>%
filter(parent %in% parentNode)

hclusters$height
```


##Collapse tree

```{r}

#This crashes on large clusters
CollapseTreetTips <- function(dend, height){
  # This function takes a dendrogram and collpses it to a specified height
  # it requires the dendextend package and the data.tree package
    #convert dendrogram to data.tree
  #Code taken from SO Answer https://stackoverflow.com/questions/41861067/collapsing-a-dendrogram-given-a-tolerance-cutoff
  print("Get nodes")
  dend.dt <- as.Node(dend)
  
  print("Get leaf vector")
  #get vector of leaves per each internal node
  node.list <- lapply(dend.dt$Get(function(node) node$leaves,filterFun = isNotLeaf),
                      function(n) unname(sapply(unlist(n,recursive = T),
                                                function(l) l$name)))
  print("Get node vector")
  #get vector of per each internal node
  node.depth.df <- data.frame(depth=c(t(sapply(Traverse(dend.dt,traversal="pre-order",
                                                        pruneFun=isNotLeaf),function(x) c(x$plotHeight)))),
                              stringsAsFactors=F)
  
  print("Drop Leaves")
  to.drop.leave.names <- c(sapply(which(node.depth.df$depth < height),function(i) node.list[[i]]))
  
  print("Convert and finish")
  #convert dendrogram to phylo
  phylo.dend <- as.phylo(dend)
  phylo.dend <- drop.tip(phylo.dend,tip=unlist(to.drop.leave.names),interactive=FALSE,trim.internal=FALSE)
  dend <- chronos(phylo.dend)
  
  return(phylo.dend)
}

```


```{r}
install.packages("data.tree")
install.packages("dendextend")
library(data.tree)
library(dendextend)



dend <- iris[1:5,-5] %>% dist %>% hclust %>% as.dendrogram

tol.level <- 0.28


dend %>% plot(horiz = TRUE); abline(v=tol.level,col="red",lty=2)
height <- tol.level

find_k(testdend)

dend <- hclusters %>% as.dendrogram
height <- 2562
test <-testdend %>% CollapseTreetTips(., 2562)


# # ladderize is like sort(..., type = "node")
dend <- iris[1:5,-5] %>% dist %>% hclust %>% as.dendrogram 
par(mfrow = c(1,3))
dend %>% ladderize %>% plot(horiz = TRUE); abline(v = .2, col = 2, lty = 2)
dend %>% collapse_branch(tol = 0.2) %>% ladderize %>% 
  plot(horiz = TRUE)
dend %>% collapse_branch(tol = 0.2) %>% #ladderize %>% 
      hang.dendrogram(hang = 0) %>% plot(horiz = TRUE)

```


#Check Electrical distance

```{r}


testmat <- rep(c(1,2,3,4),4) %>% matrix(., ncol = 4)

ElectricalDistance(testmat)


```


```{r}
 LossFractionByRound <- AllRemovedNodes %>%
  group_by(Sim, alpha, type, RoundRemoved, RemovalType) %>%
  summarise(counts = n()) %>%
  group_by(Sim, alpha, type, RemovalType) %>%
  mutate(cumsum = cumsum(counts)) %>%
  group_by(alpha, type, RoundRemoved, RemovalType) %>%
  summarise(mean = mean(counts),
            median = median(counts),
            sd = sd(counts),
            cummean = mean(cumsum),
            cummedian = median(cumsum),
            cumsd = sd(cumsum)) %>%
  left_join(tibble(type = c("Edge", "Node"), 
                    tot = c(ecount(gbase), vcount(gbase)))
            ) %>%
  group_by(alpha, type, RemovalType) %>%
  mutate( test = cumsum(median),
          testfrac = test/tot,
    cummeanfrac = cummean/tot,
            cummedianfrac = cummedian/tot)



#This plot shows that randonly attacking all nodes is LESS effective than targeting a subset of nodes in terms of islanding.
#However there is basically no overloading when targeting the subsets
LossFractionByRound %>%
  filter(RoundRemoved<100) %>% #Keep everything on rought the same scale
  filter(type == "Node", RemovalType != "Targeted") %>%
  ggplot(aes(x = RoundRemoved, y = cummean, group = alpha, colour = alpha)) + geom_line() + 
  facet_wrap(~RemovalType, scales = "free_y")
  


Loss2 <- AllRemovedNodes %>%
  group_by(Sim, alpha, type, RoundRemoved, RemovalType) %>%
  summarise(counts = n()) %>%
  group_by(Sim, alpha, type, RemovalType) %>%
  mutate(cumsum = cumsum(counts)) 


Loss2 %>%
  filter(type == "Node", RemovalType == "Islanded") %>%
  ggplot(aes(x = RoundRemoved, y = cumsum, group = Sim, colour = alpha)) + geom_line() + 
  facet_wrap(.~alpha) +
  coord_cartesian(xlim = c(0,100), ylim = c(0,300))


Loss3 <- Loss2 %>%
  group_by(Sim, type, alpha, RemovalType) %>%
  summarise(cumsum = max(cumsum)) %>%
  spread(key = RemovalType, value = cumsum)

#Strong negative corellation with between Targeted and overload for edge removal, but also for Islanded... What?
Loss3 %>%
  filter(type == "Node", alpha != "AllNodes") %>%
  ggplot(aes(x = Islanded, y = Targeted)) +
  geom_point()+ 
  facet_wrap(.~alpha)

   Loss3 %>%
 # filter(type == "Node", alpha == "Real_Limits") %>%
     group_by(alpha, type) %>%
     summarise(corTargOver = cor(Targeted, Overloaded, use =  "pairwise.complete.obs"),
               corTargIsl = cor(Targeted, Islanded, use =  "pairwise.complete.obs"),
               corOverIsl = cor(Overloaded, Islanded, use =  "pairwise.complete.obs")) %>%
     arrange(type)
   
   

   #There Only the full random attack has overloads   
 AllRemovedNodes %>%
     filter(RoundRemoved<100) %>% #Keep everything on rought the same scale
  group_by(type, alpha, Sim, RemovalType) %>%
  summarise(counts = n()) %>%
 #bind_rows(., NumberofRounds) %>%
     filter(type == "Node") %>%
   ggplot(aes(x = alpha, y = counts)) + geom_boxplot() + 
   facet_wrap(type~RemovalType, scales = "free_y") +
    theme(legend.position = "none", 
        axis.text.x = element_text(angle = 45, hjust = 1)) 


```

