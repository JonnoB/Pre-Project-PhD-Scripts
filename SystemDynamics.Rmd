---
title: "Untitled"
author: "Jonathan Bourne"
date: "22 March 2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

https://github.com/schochastics/graphlayouts

https://github.com/hackl/tikz-network


#annpotate points with rectangles
https://ggforce.data-imaginist.com/reference/geom_mark_rect.html

```{r Setup}

packages <- c("tidyverse", "igraph","readr","readxl", "broom", "stringr", "xtable", "rlang", "animation", "caret", "sf", "rgdal", "sf", "gstat", "automap", "rayshader")

new.packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

#ggtree needs to be installed seperatly 
# if (!requireNamespace("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
# BiocManager::install("ggtree", version = "3.8")
#devtools::install_github("eliocamp/ggnewscale@v0.1.0")
#devtools::install_github("eliocamp/ggnewscale")

# library(ggtree)
# library(ape)
# library(ggnewscale)


sapply(packages, library, character.only = TRUE)


lapply(packages, library, character.only = TRUE)
library(PowerGridNetworking)

#Set up file system to read the correct folders this switches between aws and windows mode

basewd <- "/home/jonno/Dropbox/Jonathan_Bourne_Phd_Folder"
datafile <- "/home/jonno/Dropbox/Jonathan_Bourne_Phd_Folder/ETYSAppendixB"
LatexFolder <- "/home/jonno/Dropbox/Apps/ShareLaTeX/Physics model for analysing flow graphs" 
FiguresFolder <- file.path(LatexFolder, "Figures")
TablesFolder <- file.path(LatexFolder, "Tables")
MatricesFolder <- file.path(LatexFolder, "Matrices")
Tariff <- file.path(basewd,"Tariff and Transport")
PLwd <- "/media/jonno/Seagate Expansion Drive/Overloads"
Deletion_Order_Folder <-  file.path("/home/jonno/Dropbox/AWS_Simulation_Files") #Only one of the deletion order folders is needed. Either Nodes or Edges


#Load necessary datasets and great the base powergrid network
source(file.path("/home/jonno/ProportionalLoading", "CreateGBase.R"))

#Load some other useful functions
list.files("/home/jonno/Useful_PhD__R_Functions", pattern = ".R", full.names = T) %>%
  walk(~source(.x))

list.files("/home/jonno/Flow_Spring_System", pattern = ".R", full.names = T) %>%
  walk(~source(.x))

VertexMetaData2 <- VertexMetaData %>%
  mutate(NodeType = case_when(
    BalencedPower>0 ~"Generator",
    BalencedPower< 0~"Demand",
    TRUE ~ "Transfer"
  ),
  NodeType2 = case_when(
    Demand>0 & Generation>0 ~"Hybrid",
    TRUE ~ NodeType
  )) %>% select(Name, NodeType, NodeType2, BalencedPower)

```


#Set up Graph
```{r}

g <- RemoveDeadEnds(gbase) #remove non-valid ends from the graph
#Ensure there is powerflow
SlackRef <- SlackRefFunc(g) #find the most appropriate node to be the slack bus
g <- PowerFlow(g, SlackRef$name) #calculate power flow

```



```{r}

EdgeNode <- c(1,-1,0,0,0,0,
              0,1,-1,0,0,0,
              0,0,0,1,-1,0,
              0,0,0,1,-1,0,
              0,0,0,0,1,-1,
              0,0,0,1,0,-1,
              0,1,0,0,-1,0
              ) %>% matrix(nrow = 7, byrow = T)

Link <- tibble(EdgeName = 1:7, 
               distance = c(sqrt(2), sqrt(2), sqrt(2), sqrt(2), 1,1, sqrt(2)),
               k = c(5,2,2.5,4,4,3,1))

  C <- matrix(data = 0, nrow = nrow(Link), ncol = nrow(Link))
  diag(C) <- Link$distance

#Injection vector of power put in and removed
InjectionVect <- c(10,20,0,-20,10,-20)
sum(InjectionVect)

InjectMat <- diag(InjectionVect)


Adj <- (t(EdgeNode) %*% diag(1, nrow = nrow(EdgeNode)) %*% EdgeNode) / (t(EdgeNode) %*% diag(1, nrow = nrow(EdgeNode)) %*% EdgeNode) 
diag(Adj) <-0
Adj[!is.finite(Adj)] <-0
Adj

graph_from_adjacency_matrix(Adj, mode = "undirected") %>% plot

Zvect <- c(1,2,0,-1,-2,-2)

HeightDiff <- t(Adj * Zvect) - (Adj * Zvect) 
D <- t(EdgeNode) %*% C %*% EdgeNode %>% abs
diag(D) <-0

kvect <- Link$k
dvect <- Link$distance

SmallEdgeNode <- matrix(c(1,-1,0,
                   0,1,-1), nrow = 2, byrow = T)
Smallzvect <- c(2,-1,1)
Smallkvect <- c(3,4)
Smalldvect <- c(1,1)

Create_Tension_matrix(SmallEdgeNode, Smallzvect, Smallkvect, Smalldvect)

Create_Tension_matrix(SmallEdgeNode, Smallzvect, Smallkvect, Smalldvect) %>%
  rowSums()


Calc_Damping_matrix(SmallEdgeNode, 0, Smallkvect, 
                    c(5,5,5))

```



```{r}

#MASS CAN'T BE ZERO!

NodeStatus2 <- tibble(node = 1:6, mass = 5, force = c(10,20,0,-20,10,-20), z = 0, 
       NetTension = 0, velocity = 0, 
       friction = 0,
       NetForce = NetTension + force - friction,
       acceleration = NetForce/mass,
       t = 0)




SmallNodeStatus <- tibble(node = 1:3, mass = 5, force = c(10,0,-10), z = 0, 
       NetTension = 0, velocity = 0, 
       friction = 0,
       NetForce = force + NetTension +friction,
       acceleration = NetForce/mass,
       t = 0)

Smalltest <-FindStabilSystem(SmallNodeStatus, SmallEdgeNode, Smallkvect, Smalldvect, tstep=0.01, maxIter = 10000, frctmultiplier = 0.01) %>%
  bind_rows()



Smalltest %>%
  group_by(t) %>%
  summarise(z = mean(abs(z)),
            NetForce = mean(abs(NetForce)),
            velocity = mean(abs(velocity)),
            acceleration = mean(abs(acceleration))) %>%
  ggplot(aes(x = t, y =z )) + geom_line()


Smalltest  %>%
  mutate(node = factor(node)) %>%
  ggplot(aes(x = t, y =z , colour = node)) + geom_line()

```


#Test real graph

```{r}
#Create Edge matrix from graph

A <- as_data_frame(List_of_BiConComps[[147]]) %>% 
  select(Link, from, to) %>% 
  gather(key = type, Node, -Link) %>%
  arrange(Node) %>%
  mutate(value = ifelse(type =="from", 1, -1)) %>%
  ungroup %>%
  select(-type) %>%
  spread(key = Node, value, fill = 0) %>%
  arrange(Link)

rowdat <- A$Link

A <- A %>% select(-Link) %>%
  as.matrix()

rownames(rowdat)

rm(rowdat)


NodeStatus <- as_data_frame(List_of_BiConComps[[147]], what = "vertices") %>%
  select(node = name, force = BalencedPower ) %>%
  mutate(
    z = 0,
    mass = 2000,
    NetTension = 0, velocity = 0, 
       friction = 0,
       NetForce = force + NetTension - friction,
       acceleration = NetForce/mass,
       t = 0) %>%
  filter(!(node %in% deletenames))

NodeStatus$force %>% sum

testratio <- NodeStatus %>%
  mutate(ratio = abs(force/mass))


Link <- as_data_frame(g) %>%
  mutate(EdgeName = Link, distance = 1/Y, alpha = Link.Limit/abs(PowerFlow),  k= 1000*(1-1/alpha)) %>% #arbitary k!
  select(EdgeName, distance, k) 

test <-FindStabilSystem(NodeStatus, A, Link$k, Link$distance, tstep= 0.5, maxIter = 2000, frctmultiplier = 1) %>%
  bind_rows()

test <-FindStabilSystem2(NodeStatus, A, Link$k, Link$distance, tstep= 0.5, maxIter = 2000, frctmultiplier = 1) 



 test$results %>%
  ggplot(aes(x = t, y =z)) + geom_line()

test2 <- test$NodeList
 
summtest <- test %>%
  group_by(t) %>%
  summarise(z = mean(abs(z)),
            NetForce = mean(abs(NetForce)),
            velocity = mean(abs(velocity)),
            acceleration = mean(abs(acceleration))) 

summtest %>%
  ggplot(aes(x = t, y = z)) + geom_line()


testnode <- test %>%
  filter(node =="DUGR")

testnode %>%
  ggplot(aes(x = t, y = z )) + geom_line()


finalround <- test %>%
  filter(t == max(t))

#k1e4 <- test
#k10 <- test
#k100Iter2k <- test

test <- k1e4

```



```{r}

#create a sub graph that includes all the bicomponent of a node except the one that includes the active bi-comp

if(file.exists(file.path()))

g <-set.edge.attribute(g, "Imp", value = 1/get.edge.attribute(g, "Y"))
g <-set.edge.attribute(g, "distance", value = 1) %>%
  Calc_Spring_Youngs_Modulus(., "PowerFlow", "Link.Limit", 400, 40) %>%
  set.edge.attribute(., "Area", value = 1)

block 83 single iteration to complete


List_of_BiConComps <- Create_balanced_blocks(g)

#use the largest block to set the simulation parameters k and m.
#k needs to be sufficiently stretch to allow enough topology variation. otherwise all that happens is a surface angled in the direct of net power flow. Which is interesting but not that interesting
OriginBlock <- Find_network_balance(List_of_BiConComps[[147]], tstep = 0.15, tol = 1e-10, distance = "distance", maxIter = 8000, mass = 5000)

OriginBlock$results %>% ggplot(aes(x = t, y = z)) + geom_line()

test <- Find_network_balance(List_of_BiConComps[[1]], tstep = 0.15, tol = 1e-10, distance = "distance", maxIter = 8000, mass = 5000)

final_z <- Create_stabilised_blocks(g, OriginBlock, 147, tstep = 0.15, tol = 1e-10, distance = "distance", maxIter = 4000, mass = 5000)

mean(final_z$z)
median(final_z$z)

#Is the strain power law distributed?
line_strain <-as_data_frame(g) %>% as_tibble %>%
  left_join(., final_z %>% select(node, z), by = c("from"= "node")) %>%
  left_join(., final_z %>% select(node, z), by = c("to"= "node")) %>%
  mutate(D = 1/Y,
         dz = abs(z.x-z.y),
         mean_z = (z.x+z.y)/2,
         H = sqrt(dz^2 +D^2),
         strain = (H-D)/D,
         alpha = Link.Limit/abs(PowerFlow),
         line_load = abs(PowerFlow)/Link.Limit,
         percentile_strain = percent_rank(strain)) %>%
  select(Link, alpha, line_load, dz, H, strain, percentile_strain, mean_z)

cor(line_strain$dz, line_strain$strain)
cor(line_strain$line_load, line_strain$strain)


test <- read_csv(file.path(basewd, "point.csv"))

z_network_map <-MakeMapDF(g, read_csv(file.path(basewd, "point.csv")))  %>%
  left_join(line_strain, by = c("Link"))%>%
   left_join(., final_z %>% select(node, z), by = c("Node"= "node")) 

z_network_map %>%
  #filter(!is.na(Perc)) %>%
    ggplot(aes(x = Longitude, y = Latitude)) + 
  geom_line(aes(group = Link, colour = percentile_strain), size = 0.8) + 
   facet_grid(~PositionType) + 
 # geom_point( aes(x = Latitude, y = Longitude, colour = percent_rank(z))) + 
  scale_color_viridis_c()+
  ggtitle("Strain map")


node_z <-z_network_map %>% as_tibble %>%
  filter(PositionType=="Geo Space") %>%
  select(Node, Longitude, Latitude, z) %>%
  distinct(.keep_all = T) 

#This is the strain of the network on each edge. It allows us to see the slope of the network
edge_strain <- 

```


#Kriging
```{r}


shapefile <- file.path("/home/jonno/Dropbox/Jonathan_Bourne_Phd_Folder/ShapeFiles UK",
                       "Countries_December_2017_Ultra_Generalised_Clipped_Boundaries_in_UK_WGS84.shp")


GB <- st_read(shapefile) %>%
  filter(ctry17cd !="N92000002") %>%
  st_union()

ggplot(GB) +
  geom_sf() +
 # scale_fill_viridis("Area") +
  ggtitle("Node locations in the UK") +
  theme_bw() +
  geom_line(data = z_network_map %>%
              filter(PositionType=="Geo Space"),  aes(x = Longitude, y = Latitude, group = Link)) +
   geom_point(data =node_z, aes(x = Longitude, y = Latitude, colour = z), alpha  = 0.7)+
  coord_sf(ylim = c(50,58.9)) +
  scale_color_viridis_c()

spdf <- as(GB, "Spatial") %>% st_as_sf %>%
  st_crop(c(xmin = -7.5, ymin = 50, xmax = 2, ymax = 59)) %>%
  as_Spatial()


test <- Create_kriged_df(node_z, "z", spdf, 8e4)

grd <- makegrid(spdf, n = 80000)
colnames(grd) <- c('x','y')

grd_pts <- SpatialPoints(coords = grd, 
                         proj4string=CRS(proj4string(spdf)))

# find all points in `grd_pts` that fall within `spdf`
grd_pts_in <- grd_pts[spdf, ]

# transform grd_pts_in back into a data frame
gdf <- as.data.frame(coordinates(grd_pts_in))


#create spatial points of height data
DT_sf  <-  st_as_sf(node_z, coords = c("Longitude", "Latitude"),
                        crs = "+proj=longlat +datum=WGS84", agr = "constant")%>% 
  as_Spatial %>%
  remove.duplicates() #remove duplicate points aka points super close

#create spatial points of data that will have z interpolated
grd_sf  <-  gdf %>% #expand.grid(x =unique(gdf$x), y = unique(gdf$y)) %>% as.tibble %>% #if expand grid isn't used problems
    rename(Longitude = x, Latitude = y) %>%
  st_as_sf(., coords = c("Longitude", "Latitude"),
                        crs = "+proj=longlat +datum=WGS84", agr = "constant") %>%
  as_Spatial


#create variogram of data
dt.vgm <- variogram(z~1, DT_sf)


#dt.fit <-fit.variogram(dt.vgm, model = vgm(1,"Lin",900,1)) # fit model

dt.fit <- autofitVariogram(z~1, 
                             DT_sf,
                             model = c("Sph"), #commenting out this autfits the variogram. that produces the lowest error but doesn't look that great. I would think the sperical one was more accurate I don't understand much about it though
                             kappa = c(0.05, seq(0.2, 2, 0.1), 5, 10),
                             fix.values = c(NA, NA, NA),
                             start_vals = c(NA,NA,NA),
                             verbose = T)

# vgm() list of models

lzn.kriged <- krige((z) ~ 1, remove.duplicates(DT_sf), grd_sf, model=dt.fit$var_mode) #remove duplicate locations


test %>% rename(Height = z) %>%
  ggplot(aes(x=Longitude, y=Latitude)) + geom_tile(aes(fill=Height)) +coord_equal() +
  scale_fill_viridis_c() +
  # geom_point(data = node_z %>% left_join(VertexMetaData2, by = c("Node"="Name")) %>%
  # filter(NodeType == "Generator") %>%
  #   rename(lat = Longitude, lon = Latitude),
  # aes(colour = BalencedPower))+
scale_colour_viridis_c(option = "plasma") +
  labs(title = "height of network across the  UK", colour = "Generation")
ggsave(file.path(FiguresFolder, "BritainKrigedTopology.pdf"))

kriged_df <- lzn.kriged %>% as.tibble %>%
  rename(Z = var1.pred) %>%
  select(-var1.var) %>%
  rename(x = coords.x1, y = coords.x2) %>%
  mutate(Z = Z/sd(Z))


kriged_df <- test %>%
  rename(x = Longitude, y = Latitude) %>%
  mutate(Z = z/sd(z))
```




#Rayshading

functions taken from

##this needs to be properly integrated and attributed
https://github.com/wcmbishop/rayshader-demo/blob/master/R/rayshader-gif.R

```{r}
#' Build a gif of 3D rayshader plots
#'
#' @param hillshade Hillshade/image to be added to 3D surface map.
#' @param heightmap A two-dimensional matrix, where each entry in the matrix is the elevation at that point.
#' @param file file path for .gif
#' @param duration gif duration in seconds (framerate will be duration/n_frames)
#' @param ... additional arguments passed to rayshader::plot_3d(). See Details for more info.
#'
#' @details This function is designed to be a pipe-in replacement for rayshader::plot_3d(),
#' but it will generate a 3D animated gif. Any inputs with lengths >1 will 
#' be interpreted as "animation" variables, which will be used to generate 
#' individual animation frames -- e.g. a vector of theta values would produce
#' a rotating gif. Inputs to plot_3d() that are meant to have length >1 
#' (specifically "windowsize") will be excluded from this process.
#'
#' @return file path of .gif file created
#' 
#' @examples
#' # MONTEREREY BAY WATER DRAINING
#' # ------------------------------
#' # define transition variables
#' n_frames <- 180
#' waterdepths <- transition_values(from = 0, to = min(montereybay), steps = n_frames) 
#' thetas <- transition_values(from = -45, to = -135, steps = n_frames)
#' # generate gif
#' zscale <- 50
#' montereybay %>% 
#'   sphere_shade(texture = "imhof1", zscale = zscale) %>%
#'   add_shadow(ambient_shade(montereybay, zscale = zscale), 0.5) %>%
#'   add_shadow(ray_shade(montereybay, zscale = zscale, lambert = TRUE), 0.5) %>%
#'   save_3d_gif(montereybay, file = "montereybay.gif", duration = 6,
#'               solid = TRUE, shadow = TRUE, water = TRUE, zscale = zscale,
#'               watercolor = "imhof3", wateralpha = 0.8, 
#'               waterlinecolor = "#ffffff", waterlinealpha = 0.5,
#'               waterdepth = waterdepths/zscale, 
#'               theta = thetas, phi = 45)
#' 
save_3d_gif <- function(hillshade, heightmap, file, duration = 5, ...) {
  require(rayshader)
  require(magick)
  require(rgl)
  require(gifski)
  require(rlang)
  
  # capture dot arguments and extract variables with length > 1 for gif frames
  dots <- rlang::list2(...)
  var_exception_list <- c("windowsize")
  dot_var_lengths <- purrr::map_int(dots, length)
  gif_var_names <- names(dots)[dot_var_lengths > 1 & 
                                 !(names(dots) %in% var_exception_list)]
  # split off dot variables to use on gif frames
  gif_dots <- dots[gif_var_names]
  static_dots <- dots[!(names(dots) %in% gif_var_names)]
  gif_var_lengths <- purrr::map_int(gif_dots, length)
  # build expressions for gif variables that include index 'i' (to use in the for loop)
  gif_expr_list <- purrr::map(names(gif_dots), ~rlang::expr(gif_dots[[!!.x]][i]))
  gif_exprs <- exprs(!!!gif_expr_list)
  names(gif_exprs) <- names(gif_dots)
  message(paste("gif variables found:", paste(names(gif_dots), collapse = ", ")))
  
  # TODO - can we recycle short vectors?
  if (length(unique(gif_var_lengths)) > 1) 
    stop("all gif input vectors must be the same length")
  n_frames <- unique(gif_var_lengths)
  
  # generate temp .png images
  temp_dir <- tempdir()
  img_frames <- file.path(temp_dir, paste0("frame-", seq_len(n_frames), ".png"))
  on.exit(unlink(img_frames))
  message(paste("Generating", n_frames, "temporary .png images..."))
  for (i in seq_len(n_frames)) {
    message(paste(" - image", i, "of", n_frames))
    rgl::clear3d()
    hillshade %>%
      plot_3d_tidy_eval(heightmap, !!!append(gif_exprs, static_dots))
    rgl::snapshot3d(img_frames[i])
  }
  
  # build gif
  message("Generating .gif...")
  magick::image_write_gif(magick::image_read(img_frames), 
                          path = file, delay = duration/n_frames)
  message("Done!")
  invisible(file)
}


plot_3d_tidy_eval <- function(hillshade, ...) {
  dots <- rlang::enquos(...)
  plot_3d_call <- rlang::expr(plot_3d(hillshade, !!!dots))
  rlang::eval_tidy(plot_3d_call)
}


#' Create a numeric vector of transition values.
#' @description This function helps generate a sequence 
#' of numeric values to transition "from" a start point
#' "to" some end point. The transition can be "one_way" 
#' (meaning it ends at the "to" point) or "two_way" (meaning
#' we return back to end at the "from" point).
#'
#' @param from starting point for transition values
#' @param to ending point (for one-way transitions) or turn-around point 
#'           (for two-way transitions)
#' @param steps the number of steps to take in the transation (i.e. the length
#'              of the returned vector)
#' @param one_way logical value to determine if we should stop at the "to" value
#'                (TRUE) or turn around and return to the "from" value (FALSE)
#' @param type string defining the transition type - currently suppoerts "cos"
#'             (for a cosine curve) and "lin" (for linear steps)
#'
#' @return a numeric vector of transition values
#' 
transition_values <- function(from, to, steps = 10, 
                              one_way = FALSE, type = "cos") {
  if (!(type %in% c("cos", "lin")))
    stop("type must be one of: 'cos', 'lin'")
  
  range <- c(from, to)
  middle <- mean(range)
  half_width <- diff(range)/2
  
  # define scaling vector starting at 1 (between 1 to -1)
  if (type == "cos") {
    scaling <- cos(seq(0, 2*pi / ifelse(one_way, 2, 1), length.out = steps))
  } else if (type == "lin") {
    if (one_way) {
      xout <- seq(1, -1, length.out = steps)
    } else {
      xout <- c(seq(1, -1, length.out = floor(steps/2)), 
                seq(-1, 1, length.out = ceiling(steps/2)))
    }
    scaling <- approx(x = c(-1, 1), y = c(-1, 1), xout = xout)$y 
  }
  
  middle - half_width * scaling
}

```

##create 3D plot
```{r}

{
kriged_df3 <- kriged_df %>%
  spread(key = x, value = Z, fill = min(kriged_df$Z)-2) 

x <- names(kriged_df3)[-1]  %>% as.numeric()
y <- kriged_df3 %>% pull(y)

kriged_df3 <- kriged_df3 %>%
  select(-y) %>% as.matrix()
}

elev_matrix <- (kriged_df3)*100

ambmat <- ambient_shade(elev_matrix, zscale = 20)
raymat <- ray_shade(elev_matrix, zscale = 20, lambert = TRUE)
watermap <- detect_water(elev_matrix)

elev_matrix %>%
  sphere_shade(texture = "imhof1") %>%
  add_water(watermap, color = "imhof4") %>%
  add_shadow(raymat, max_darken = 0.5) %>%
  add_shadow(ambmat, max_darken = 0.5) %>%
  plot_3d(elev_matrix, zscale = 20, theta = -45, phi = 45, water = FALSE,
          windowsize = c(1000,800), zoom = 0.75, waterlinealpha = 0.3,
          wateralpha = 0.5, watercolor = "lightblue", waterlinecolor = "white")
#%>% render_snapshot() # Save image to current path




```

##animate
```{r}
n_frames <- 180
zscale <-20
waterdepths <- transition_values(from = min(elev_matrix) + 2, to = 0, steps = n_frames) 
thetas <- transition_values(from = -65, to = -115, steps = n_frames)
# generate gif
elev_matrix %>% 
  sphere_shade(texture = "imhof1", zscale = 1) %>%
  add_shadow(raymat, max_darken = 0.5) %>%
  add_shadow(ambmat, max_darken = 0.5) %>%
  save_3d_gif(elev_matrix, file = "GB.gif", duration = 5,
              solid = TRUE, shadow = TRUE, water = TRUE, zscale = zscale,
              watercolor = "imhof3", wateralpha = 0.8, 
              waterlinecolor = "#ffffff", waterlinealpha = 0.5,
              waterdepth = waterdepths/zscale, 
              theta = thetas, phi = 45)




#orig
elev_matrix %>% 
  sphere_shade(texture = "imhof1", zscale = zscale) %>%
  add_shadow(raymat, max_darken = 0.5) %>%
  add_shadow(ambmat, max_darken = 0.5) %>%
  save_3d_gif(elev_matrix, file = "GB.gif", duration = 6,
              solid = TRUE, shadow = TRUE, water = TRUE, zscale = zscale,
              watercolor = "imhof3", wateralpha = 0.8, 
              waterlinecolor = "#ffffff", waterlinealpha = 0.5,
              waterdepth = waterdepths/zscale, 
              theta = thetas, phi = 45)

```



#Extended model


##Distance clusters

```{r}
z_graph <- as_data_frame(g) %>% as_tibble %>%
  left_join(., final_z %>% select(node, z), by = c("from"= "node")) %>%
  left_join(., final_z %>% select(node, z), by = c("to"= "node")) %>%
  mutate(D = 1/Y,
         dz = abs(z.x-z.y),
         mean_z = (z.x+z.y)/2,
         H = sqrt(dz^2 +D^2),
         strain = (H-D)/D,
         alpha = Link.Limit/abs(PowerFlow),
         line_load = abs(PowerFlow)/Link.Limit,
         percentile_strain = percent_rank(strain)) %>%
graph_from_data_frame(., vertices = node_z %>% select(Node, z), directed = FALSE ) 

z_mst <- mst(z_graph, weights = get.edge.attribute(z_graph, "dz"))

FailureNodeCommunity_z  <- z_graph %>% 
  cluster_walktrap(.) %>% 
  MakeNodeCommunity()

IsSameCommunity2(FailureNodeCommunity, FailureNodeCommunity_z) %>% pull(Jaccard) %>% mean

distancedf <- distances(g, weights = get.edge.attribute(g, "dz")) %>% as_tibble %>% mutate(from = names(.)) %>%
    gather(key = "to", value = "distance",-from)

#graph clustered based on height distance
distgraph <- distancedf %>% spread(to, distance) %>% select(-from) %>% as.matrix
rownames(distgraph) <- colnames(distgraph)
dist_hclust <- distgraph %>% as.dist %>% hclust(.) 

dist_hclust <- hclust_graph(z_mst)

#True co-failure group
hclust_nodes1 <- hclust_graph(g_cofailure, weight = "weight") %>%
  list(names = names(cutree(., 10)),  membership = cutree(., 10)) %>%
  MakeNodeCommunity(large = 1, medium = 0)

hclust_nodes2 <- hclust_graph(g) %>%
  list(names = names(cutree(., 10)),  membership = cutree(., 12)) %>%
  MakeNodeCommunity(large = 1, medium = 0)

#stress group
hclust_nodes3 <- hclust_graph(z_graph, weight = "H") %>%
  list(names = names(cutree(., 10)),  membership = cutree(., 10)) %>%
  MakeNodeCommunity(large = 1, medium = 0)

#topological
hclust_nodes4 <-  g %>% set.edge.attribute(., "weight", value = rep(1, ecount(.))) %>% #set edge weights to 1
hclust_graph(., weight = "weight")  %>%
  list(names = names(cutree(., 10)),  membership = cutree(., 10)) %>%
  MakeNodeCommunity(large = 1, medium = 0)

MakeMapDF(g, read_csv(file.path(basewd, "point.csv")))  %>%
  left_join(hclust_nodes1) %>%
#  left_join(VertexMetaData2 %>% rename(Node = Name)) %>%
    ggplot(aes(x = Latitude, y = Longitude)) + 
  geom_line(aes(group = Link), size = 0.8) + 
  geom_point(aes(colour =Community), size = 2) +
   facet_grid(~PositionType) +
    scale_color_brewer(palette = "Paired")+
  labs(title = "Failure groups hierarchically clustered 10 groups")


#There is a strong corellation betweeen Longitude and z and no corellation between latitude and z
node_z %>%
  gather(key = coord, value = value, -z,-Node) %>%
  left_join(final_z %>% select(node, NetTension), by = c("Node"= "node")) %>%
  left_join(hclust_nodes1) %>%
  mutate(Force = percent_rank(abs(NetTension))) %>%
  ggplot(aes(x = value, y = z, colour = Force)) + geom_point() + 
  scale_color_viridis_c() +
  #scale_color_brewer(palette = "Paired")+
  facet_grid(~coord, scales = "free_x") +
  labs(title = "The height of each node and the percent rank Force acting on each node \n relative to the Latitude and Longitude")


node_z %>%
  gather(key = coord, value = value, -z,-Node) %>%
  left_join(final_z %>% select(node, NetTension), by = c("Node"= "node")) %>%
  left_join(hclust_nodes1) %>%
  ggplot(aes(x = value, y = z, colour = Community)) + geom_point() + 
  scale_color_brewer(palette = "Paired")+
  facet_grid(~coord, scales = "free_x") +
  labs(title = "Node cluster membership")

CommSim <- IsSameCommunity2(hclust_nodes1, hclust_nodes3) %>%
  left_join(hclust_nodes2, by = c("Node"= "Node")) %>%
  group_by(membership) %>%
  summarise(Jaccard = mean(Jaccard),
            size = first(size),
            rank = first(rank) %>% as.integer,
            Community = first(Community))



test <-Tree_Similarity(hclust_graph(z_graph, weight = "dz") , 
                       hclust_graph(g_cofailure, weight = "weight"),1,50) %>%
  mutate(type = "depth") %>%
  bind_rows(Tree_Similarity( hclust_graph(g), 
                       hclust_graph(g_cofailure, weight = "weight"),1,50) %>%
  mutate(type = "Line Limit")) %>%
  # bind_rows(Tree_Similarity( hclust_graph(z_mst, weight = "dz"), 
  #                      hclust_graph(g_cofailure, weight = "weight"),1, 50) %>%
  # mutate(type = "mst depth")) %>%
    bind_rows(Tree_Similarity(g %>% set.edge.attribute(., "weight", value = rep(1, ecount(.))) %>% #set edge weights to 1
hclust_graph(., weight = "weight") , 
                       hclust_graph(g_cofailure, weight = "weight"),1, 50) %>%
  mutate(type = "topological")) %>%
  bind_rows(Tree_Similarity( hclust_graph(z_graph, weight = "H"), 
                       hclust_graph(g_cofailure, weight = "weight"),1, 50) %>%
  mutate(type = "H dist")) 
  


test %>%
  filter(trees>3) %>%
  ggplot(aes(x = trees, y = mean, colour = type )) + geom_line()

Tree_Similarity(hclust_graph(z_graph, weight = "dz") , 
                       hclust_graph(g_cofailure, weight = "weight"),10,10, node_jaccard = T) %>%
  ggplot(aes(x = Jaccard)) + geom_density()

```

```{r}

test2 <- OverloadType %>%
  filter(type == "Edge") %>% 
  left_join(as_data_frame(z_graph)%>%as.tibble, by = c("Name"="name"))%>%  ungroup 
   
select(test2, Islanded, Overloaded, Targeted, mean_z, H, line_load, strain, percentile_strain, dz) %>% cor

g_cofailure <- DistDF %>%
  select(Node1, Node2, weight = counts) %>%
  filter(weight >=1000) %>% #only edges with at least 1000 occurrances aka 10%, I'm not sure on the rights and wrongs of a cut off. This is definately a case for the metric backbone. Doing this or not makes a substantial difference
  graph_from_data_frame(directed = FALSE)


```



```{r}

node_heights <- tibble(node = get.vertex.attribute(z_mst, "name"), z = get.vertex.attribute(z_mst, "z")) %>%
  mutate(rank = rank(z))

remove_nodes <- node_heights %>%
  filter(rank>2) %>% pull(node)

g_temp <- delete.vertices(z_mst, remove_nodes) 
plot(g_temp)

g_non_single <- delete.vertices(g_temp, get.vertex.attribute(g_temp,"name" )[degree(g_temp)==0])

who_is_with_who <- tibble(name = names(components(g_non_single)$membership), component = components(g_non_single)$membership)


#how to make a hclust object
a <- list()  # initialize empty object
# define merging pattern: 
#    negative numbers are leaves, 
#    positive are merged clusters (defined by row number in $merge)
a$merge <- matrix(c(-1, -2,
                    -3, -4,
                     1,  2), nc=2, byrow=TRUE ) 
a$height <- c(1, 1.5, 3)    # define merge heights
a$order <- 1:4              # order of leaves(trivial if hand-entered)
a$labels <- LETTERS[1:4]    # labels of leaves
class(a) <- "hclust"        # make it an hclust object
plot(a)                     # look at the result   

#convert to a dendrogram object if needed
ad <- as.dendrogram(a)

```



The extended model replaces k with functions for A and E. This arguably allows a more robust and flexible model.

E is a function of line loading 
A is a logistic function of free capacity and initial flow

```{r}

eta <- 5
gamma <- 5
midpoint <- 5
k <- 1
x <- seq(-10, 10, by = .01)

calc_beta <- function(Force, Total_Free_Capacity, Free_Capacity){
  
  
 Fi - Fi/(Total_Free_Capacity - Free_Capacity)
  
}

Freecapi <- 0
FreeCap <- seq(Freecapi, 30, 0.1)
x <- calc_beta(10, FreeCap, Freecapi)


Area_df <- tibble(FreeCap, x, logisitc = 1/(1+exp(-k*(x-midpoint))), eta, gamma, final_curve = eta*logisitc + gamma)

Area_df %>%
ggplot(aes(x = FreeCap,y = final_curve)) + geom_line()



test <- Calc_logistic_Spring_Area(g, "PowerFlow", "Link.Limit", .1, 2, .1) %>%
  as_data_frame() %>% mutate(absFlow = abs(PowerFlow))

test %>% 
  ggplot(aes(x = Area/abs(PowerFlow), y = abs(abs(PowerFlow)/Link.Limit))) + geom_point()


minimum_value <- 100
stretch_ratio <-10


test2 <- Calc_Spring_Youngs_Modulus(g, "PowerFlow", "Link.Limit", 100, 10) %>%
  Calc_logistic_Spring_Area(., "PowerFlow", "Link.Limit", .1, 2, .1) %>%
  as_data_frame() %>% mutate(absFlow = abs(PowerFlow))

test2 %>% 
  ggplot(aes(x = E, y = abs(abs(PowerFlow)/Link.Limit))) + geom_point()

test2 %>%
  ggplot(aes(x =E )) + geom_density()

test2 %>% 
  ggplot(aes(x = E, y = Area/abs(PowerFlow), colour = percent_rank(abs(PowerFlow)))) + geom_point() +
  scale_color_viridis_c()


```



#fixed alpha and weigted alpha

The resultant thetas from an example group should be plotted

make graph
fix flow
create a function that replaces the capcity and finds convergance.

```{r}

test <- expand.grid(A= 20:80, B= 10:70, C =10:70) %>%
  as.tibble %>% mutate(total = rowSums(.)) %>%
filter(total == 100) %>%
  select(-total) %>%
  mutate(groupID = 1:n()) %>%
  gather(key = edge, value = capacity, - groupID) %>%
  left_join(tibble(edge = c("A", "B", "C"), 
                   flow = c(20,10,10)), 
            by = "edge") %>%
  mutate(alpha = capacity/flow) %>%
  group_by(groupID) %>%
  mutate(mean_alpha = mean(alpha), 
         flow_fract = flow/sum(flow),
         excess_cap = sum(alpha*flow_fract)/3) %>%
  group_by(mean_alpha) %>%
  mutate(counts = n(),
         rank = rank(excess_cap, ties.method = "random"))


test %>% select(edge, capacity, mean_alpha, groupID) %>%
  spread(key = edge, value = capacity)

#for a fixed value of A weighted alpha is fixed when excess capacity moves between B and C as they have the same flow and capacity.
#However the theta value will be different
#This is somehow related to entropy
test %>% group_by(groupID) %>% 
  summarise_all(first) %>%
  ggplot(aes(x = mean_alpha)) + geom_density()
  filter(rank == 1)

```

